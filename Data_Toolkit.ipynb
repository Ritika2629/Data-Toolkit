{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Data Toolkit**"
      ],
      "metadata": {
        "id": "xzxwswdIeaKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Theoretical questions**"
      ],
      "metadata": {
        "id": "_6uFGQ6EefnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.What is NumPy, and why is it widely used in Python ?"
      ],
      "metadata": {
        "id": "nw2vEc5DK3uR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXSNnn7RKnJB"
      },
      "outputs": [],
      "source": [
        "#What is NumPy?\n",
        "\n",
        "NumPy (Numerical Python) is a fundamental library for numerical computing in Python. It provides support for:\n",
        "\n",
        "- Multidimensional arrays: Efficient storage and manipulation of large datasets.\n",
        "- Mathematical operations: Tools for performing mathematical computations on arrays, such as addition, subtraction, multiplication, division, and more complex operations like linear algebra and Fourier transforms.\n",
        "\n",
        "NumPy is open-source and widely used in fields such as data science, machine learning, scientific computing, and engineering.\n",
        "\n",
        "#Key Features of NumPy\n",
        "1.N-dimensional Arrays:\n",
        "\n",
        "- At the core of NumPy is the ndarray object, which supports arrays of any dimension.\n",
        "- Arrays are more efficient than Python lists in terms of memory usage and performance.\n",
        "\n",
        "2.Vectorized Operations:\n",
        "\n",
        "- NumPy allows you to perform element-wise operations on arrays without the need for loops, enabling faster execution.\n",
        "\n",
        "3.Broadcasting:\n",
        "\n",
        "- Allows operations between arrays of different shapes, simplifying many mathematical computations.\n",
        "\n",
        "4.Mathematical Functions:\n",
        "\n",
        "- Includes a wide range of functions for performing mathematical operations, such as trigonometry, statistics, and linear algebra.\n",
        "\n",
        "5.Integration with Other Libraries:\n",
        "\n",
        "- Works seamlessly with libraries like Pandas, Matplotlib, and Scikit-learn.\n",
        "\n",
        "6.High Performance:\n",
        "\n",
        "- Operations in NumPy are implemented in C, making them faster than equivalent Python code.\n",
        "\n",
        "#Why is NumPy Widely Used?\n",
        "1.Performance:\n",
        "\n",
        "- NumPy arrays are more memory-efficient and faster than Python lists due to their homogeneous data type and optimized implementations.\n",
        "\n",
        "2.Ease of Use:\n",
        "\n",
        "- The API is simple and consistent, making it easy to learn and use.\n",
        "\n",
        "3.Extensibility:\n",
        "\n",
        "- NumPy can be extended to integrate with libraries like TensorFlow and PyTorch for deep learning applications.\n",
        "\n",
        "4.Foundation for Data Science and Machine Learning:\n",
        "\n",
        "- Provides the numerical foundation for many Python libraries such as Pandas (data manipulation) and SciPy (scientific computing).\n",
        "\n",
        "5.Broad Community Support:\n",
        "\n",
        "- NumPy has a large and active community, ensuring continuous development, tutorials, and resources.\n",
        "\n",
        "#Example Usage\n",
        "\n",
        "Creating a NumPy Array\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Create a 1D array\n",
        "array = np.array([1, 2, 3, 4, 5])\n",
        "print(array)\n",
        "\n",
        "#Performing Mathematical Operations\n",
        "\n",
        "# Element-wise addition\n",
        "array = np.array([1, 2, 3])\n",
        "result = array + 5\n",
        "print(result)  # Output: [6 7 8]\n",
        "\n",
        "#Linear Algebra Example\n",
        "\n",
        "# Matrix multiplication\n",
        "matrix1 = np.array([[1, 2], [3, 4]])\n",
        "matrix2 = np.array([[5, 6], [7, 8]])\n",
        "result = np.dot(matrix1, matrix2)\n",
        "print(result)\n",
        "\n",
        "#Statistical Operations\n",
        "\n",
        "data = np.array([10, 20, 30, 40])\n",
        "print(\"Mean:\", np.mean(data))\n",
        "print(\"Standard Deviation:\", np.std(data))\n",
        "\n",
        "#Conclusion\n",
        "NumPy is a powerful tool for numerical computation, offering efficiency, simplicity, and a vast array of functionalities. Its role as the backbone of many Python data analysis and scientific computing libraries makes it indispensable for developers and researchers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.How does broadcasting work in NumPy ?"
      ],
      "metadata": {
        "id": "57vhaPpONfxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Broadcasting in NumPy\n",
        "\n",
        "Broadcasting is a powerful feature in NumPy that allows operations on arrays of different shapes. Instead of reshaping arrays manually to match their dimensions, broadcasting automatically aligns arrays by \"stretching\" their shapes where possible.\n",
        "\n",
        "#Key Concept\n",
        "Broadcasting allows NumPy to perform element-wise operations on arrays of different shapes by following specific rules to make their shapes compatible. It avoids creating large, memory-intensive intermediate arrays.\n",
        "\n",
        "#Rules of Broadcasting\n",
        "1.Aligning Shapes:\n",
        "\n",
        "- Starting from the rightmost dimensions, compare the shapes of the two arrays.\n",
        "- Two dimensions are compatible if:\n",
        "  - They are equal, or\n",
        "  - One of them is 1.\n",
        "2.Expanding Dimensions:\n",
        "\n",
        "- If a dimension is 1, it can be \"stretched\" to match the corresponding dimension of the other array.\n",
        "3.Shape Mismatch:\n",
        "\n",
        "- If the dimensions are not compatible (and one is not 1), broadcasting results in an error.\n",
        "\n",
        "#Examples of Broadcasting\n",
        "\n",
        "Example 1: Adding a Scalar to an Array\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Array and scalar\n",
        "array = np.array([1, 2, 3])\n",
        "scalar = 5\n",
        "\n",
        "# Broadcasting adds 5 to each element\n",
        "result = array + scalar\n",
        "print(result)  # Output: [6 7 8]\n",
        "\n",
        "Example 2: Adding Arrays of Different Shapes\n",
        "\n",
        "# 2D array\n",
        "array1 = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "# 1D array\n",
        "array2 = np.array([10, 20, 30])\n",
        "\n",
        "# Broadcasting aligns shapes and performs addition\n",
        "result = array1 + array2\n",
        "print(result)\n",
        "\n",
        "Output:\n",
        "\n",
        "[[11 22 33]\n",
        " [14 25 36]]\n",
        "\n",
        "Here:\n",
        "\n",
        "- array1 has shape (2, 3)\n",
        "- array2 has shape (3,)\n",
        "- The second array is broadcasted to (2, 3) to match array1.\n",
        "\n",
        "#Example 3: Column Vector with Row Vector\n",
        "\n",
        "# Column vector (2D array)\n",
        "array1 = np.array([[1], [2], [3]])\n",
        "\n",
        "# Row vector (1D array)\n",
        "array2 = np.array([10, 20, 30])\n",
        "\n",
        "# Broadcasting aligns shapes and performs addition\n",
        "result = array1 + array2\n",
        "print(result)\n",
        "\n",
        "Output:\n",
        "\n",
        "[[11 21 31]\n",
        " [12 22 32]\n",
        " [13 23 33]]\n",
        "Here:\n",
        "\n",
        "array1 has shape (3, 1)\n",
        "array2 has shape (1, 3)\n",
        "Broadcasting expands both to shape (3, 3).\n",
        "\n",
        "#Example 4: Shape Mismatch Error\n",
        "\n",
        "array1 = np.array([1, 2, 3])\n",
        "array2 = np.array([1, 2])\n",
        "\n",
        "# This will raise a ValueError\n",
        "result = array1 + array2\n",
        "\n",
        "Error:\n",
        "\n",
        "ValueError: operands could not be broadcast together with shapes (3,) (2,)\n",
        "\n",
        "Here, the shapes (3,) and (2,) are incompatible because they cannot be aligned.\n",
        "\n",
        "#Practical Applications of Broadcasting\n",
        "1.Vectorized Operations:\n",
        "\n",
        "- Simplifies element-wise operations on arrays without writing explicit loops.\n",
        "2.Arithmetic Operations:\n",
        "\n",
        "- Adds, subtracts, multiplies, or divides arrays with different shapes.\n",
        "3.Statistical Operations:\n",
        "\n",
        "- Compute row-wise or column-wise statistics using broadcasting.\n",
        "\n",
        "#How Broadcasting Works Internally\n",
        "Broadcasting does not actually replicate data. Instead, it uses strides and other optimization techniques to avoid memory overhead. This makes broadcasting operations efficient.\n",
        "\n",
        "#Conclusion\n",
        "Broadcasting in NumPy is a convenient and efficient feature that simplifies array operations. By automatically aligning shapes according to specific rules, it allows you to write cleaner, more readable, and faster code without manually reshaping arrays."
      ],
      "metadata": {
        "id": "Bhpy-hRLNpl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.What is a Pandas DataFrame ?"
      ],
      "metadata": {
        "id": "6rWjgR8LWag8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#What is a Pandas DataFrame?\n",
        "\n",
        "A Pandas DataFrame is a two-dimensional, size-mutable, and heterogeneous data structure in Python. It is one of the core data structures provided by the Pandas library for data manipulation and analysis. A DataFrame is similar to a table or spreadsheet, where data is organized in rows and columns.\n",
        "\n",
        "#Key Characteristics of a Pandas DataFrame\n",
        "1.Two-Dimensional:\n",
        "\n",
        "- A DataFrame has rows and columns, which can store data of different types (e.g., integers, floats, strings).\n",
        "2.Labeled Axes:\n",
        "\n",
        "- Rows and columns are labeled, making it easy to index, slice, and manipulate data.\n",
        "3.Heterogeneous:\n",
        "\n",
        "- Different columns in a DataFrame can hold data of different types.\n",
        "4.Size-Mutable:\n",
        "\n",
        "- You can add or remove rows and columns dynamically.\n",
        "5.Indexing:\n",
        "\n",
        "- Each row has an associated index label, and each column has a name, which allows for intuitive and flexible access to data.\n",
        "\n",
        "#Creating a Pandas DataFrame\n",
        "A DataFrame can be created from various data sources, such as:\n",
        "\n",
        "- Lists or dictionaries\n",
        "- Numpy arrays\n",
        "- CSV files\n",
        "- Excel sheets\n",
        "- Databases\n",
        "\n",
        "Example 1: Creating a DataFrame from a Dictionary\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'Age': [25, 30, 35],\n",
        "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "Output:\n",
        "\n",
        "      Name  Age         City\n",
        "0    Alice   25     New York\n",
        "1      Bob   30  Los Angeles\n",
        "2  Charlie   35      Chicago\n",
        "\n",
        "Example 2: Creating a DataFrame from a List of Lists\n",
        "\n",
        "data = [\n",
        "    ['Alice', 25, 'New York'],\n",
        "    ['Bob', 30, 'Los Angeles'],\n",
        "    ['Charlie', 35, 'Chicago']\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(data, columns=['Name', 'Age', 'City'])\n",
        "print(df)\n",
        "\n",
        "Output:\n",
        "\n",
        "      Name  Age         City\n",
        "0    Alice   25     New York\n",
        "1      Bob   30  Los Angeles\n",
        "2  Charlie   35      Chicago\n",
        "\n",
        "#Accessing Data in a DataFrame\n",
        "1.Accessing Columns:\n",
        "\n",
        "print(df['Name'])  # Access the 'Name' column\n",
        "\n",
        "2.Accessing Rows:\n",
        "\n",
        "print(df.loc[0])  # Access the first row by label\n",
        "print(df.iloc[0])  # Access the first row by position\n",
        "\n",
        "3.Accessing Specific Elements:\n",
        "\n",
        "print(df.at[0, 'Name'])  # Access element by label\n",
        "print(df.iat[0, 0])      # Access element by position\n",
        "\n",
        "#Why Use Pandas DataFrame?\n",
        "1.Data Organization:\n",
        "\n",
        "- Tabular structure makes it intuitive to manipulate data.\n",
        "2.Powerful Indexing:\n",
        "\n",
        "- Labeled axes simplify data selection, filtering, and grouping.\n",
        "3.Efficient Operations:\n",
        "\n",
        "- Pandas is optimized for handling large datasets.\n",
        "4.Data Manipulation:\n",
        "\n",
        "- Easily perform operations like sorting, merging, joining, and reshaping data.\n",
        "5.Integration:\n",
        "\n",
        "- Works seamlessly with other Python libraries like NumPy, Matplotlib, and Scikit-learn.\n",
        "\n",
        "#Common Operations on DataFrames\n",
        "1.Filtering Data:\n",
        "\n",
        "print(df[df['Age'] > 25])  # Filter rows where Age > 25\n",
        "\n",
        "2.Adding Columns:\n",
        "\n",
        "df['Salary'] = [50000, 60000, 70000]\n",
        "print(df)\n",
        "\n",
        "3.Dropping Columns:\n",
        "\n",
        "df = df.drop('City', axis=1)\n",
        "print(df)\n",
        "\n",
        "4.Aggregations:\n",
        "\n",
        "print(df['Age'].mean())  # Calculate mean of the Age column\n",
        "\n",
        "5.Sorting:\n",
        "\n",
        "df = df.sort_values(by='Age')\n",
        "print(df)\n",
        "\n",
        "#Conclusion\n",
        "A Pandas DataFrame is a versatile and powerful tool for working with structured data in Python. It provides an intuitive interface for data analysis and manipulation, making it a key component in data science workflows."
      ],
      "metadata": {
        "id": "m7VrrEMYWo15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.Explain the use of the groupby() method in Pandas ?"
      ],
      "metadata": {
        "id": "fNPGD_DlZiwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "The groupby() Method in Pandas\n",
        "\n",
        "The groupby() method in Pandas is a powerful tool for grouping data based on one or more keys (columns). It allows you to perform split-apply-combine operations, where:\n",
        "\n",
        "1.Split: The data is split into groups based on a specified key or column.\n",
        "2.Apply: A function is applied to each group (e.g., aggregation, transformation, or filtering).\n",
        "3.Combine: The results of the applied function are combined into a single DataFrame or Series.\n",
        "\n",
        "This functionality is essential for analyzing and summarizing datasets in a structured way.\n",
        "\n",
        "Syntax\n",
        "\n",
        "DataFrame.groupby(by, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=NoDefault.no_default, observed=False, dropna=True)\n",
        "\n",
        "- by: Specifies the column(s) to group by (e.g., column name, list of column names, or a function).\n",
        "- axis: Default is 0 (group rows); can also group columns by setting it to 1.\n",
        "- as_index: If True (default), the group labels are used as the index; if False, they remain as columns.\n",
        "- sort: Sorts the groups by group keys if True (default).\n",
        "- level: Group by a specific level in a MultiIndex.\n",
        "\n",
        "#Examples of groupby() Usage\n",
        "1. Grouping and Aggregating Data\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Department': ['HR', 'IT', 'HR', 'IT', 'Finance', 'Finance'],\n",
        "    'Employee': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank'],\n",
        "    'Salary': [60000, 80000, 55000, 70000, 75000, 72000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Group by 'Department' and calculate mean salary\n",
        "grouped = df.groupby('Department')['Salary'].mean()\n",
        "print(grouped)\n",
        "\n",
        "Output:\n",
        "\n",
        "Department\n",
        "Finance    73500.0\n",
        "HR         57500.0\n",
        "IT         75000.0\n",
        "Name: Salary, dtype: float64\n",
        "\n",
        "2. Grouping by Multiple Columns\n",
        "\n",
        "# Group by 'Department' and 'Employee' and sum salaries\n",
        "grouped = df.groupby(['Department', 'Employee'])['Salary'].sum()\n",
        "print(grouped)\n",
        "\n",
        "Output:\n",
        "\n",
        "Department  Employee\n",
        "Finance     Eve        75000\n",
        "            Frank      72000\n",
        "HR          Alice      60000\n",
        "            Charlie    55000\n",
        "IT          Bob        80000\n",
        "            David      70000\n",
        "Name: Salary, dtype: int64\n",
        "\n",
        "3. Applying Multiple Aggregation Functions\n",
        "\n",
        "# Aggregate multiple functions\n",
        "aggregated = df.groupby('Department')['Salary'].agg(['mean', 'sum', 'max'])\n",
        "print(aggregated)\n",
        "\n",
        "Output:\n",
        "\n",
        "                mean    sum    max\n",
        "Department\n",
        "Finance      73500.0  147000  75000\n",
        "HR           57500.0  115000  60000\n",
        "IT           75000.0  150000  80000\n",
        "\n",
        "4. Iterating Over Groups\n",
        "\n",
        "# Iterate through groups\n",
        "grouped = df.groupby('Department')\n",
        "for group_name, group_data in grouped:\n",
        "    print(f\"Group: {group_name}\")\n",
        "    print(group_data)\n",
        "\n",
        "Output:\n",
        "\n",
        "Group: Finance\n",
        "  Department Employee  Salary\n",
        "4    Finance      Eve   75000\n",
        "5    Finance    Frank   72000\n",
        "\n",
        "Group: HR\n",
        "  Department Employee  Salary\n",
        "0        HR    Alice   60000\n",
        "2        HR  Charlie   55000\n",
        "\n",
        "Group: IT\n",
        "  Department Employee  Salary\n",
        "1        IT      Bob   80000\n",
        "3        IT    David   70000\n",
        "\n",
        "5. Transformations\n",
        "The transform() method applies a function to each group and returns a DataFrame with the same shape as the original.\n",
        "\n",
        "# Add a column with normalized salaries by department\n",
        "df['Normalized_Salary'] = df.groupby('Department')['Salary'].transform(lambda x: x / x.sum())\n",
        "print(df)\n",
        "\n",
        "Output:\n",
        "\n",
        "  Department Employee  Salary  Normalized_Salary\n",
        "0        HR    Alice   60000           0.521739\n",
        "1        IT      Bob   80000           0.533333\n",
        "2        HR  Charlie   55000           0.478261\n",
        "3        IT    David   70000           0.466667\n",
        "4    Finance      Eve   75000           0.510204\n",
        "5    Finance    Frank   72000           0.489796\n",
        "\n",
        "6. Filtering Groups\n",
        "The filter() method keeps groups that satisfy a condition.\n",
        "\n",
        "# Keep only departments with an average salary above 60000\n",
        "filtered = df.groupby('Department').filter(lambda x: x['Salary'].mean() > 60000)\n",
        "print(filtered)\n",
        "\n",
        "Output:\n",
        "\n",
        "  Department Employee  Salary\n",
        "1        IT      Bob   80000\n",
        "3        IT    David   70000\n",
        "4    Finance      Eve   75000\n",
        "5    Finance    Frank   72000\n",
        "\n",
        "#When to Use groupby()?\n",
        "- Aggregating data (e.g., sum, mean, median).\n",
        "- Applying custom functions to groups.\n",
        "- Transforming data within groups.\n",
        "- Filtering subsets of data based on group properties.\n",
        "\n",
        "#Conclusion\n",
        "The groupby() method is essential for working with structured datasets in Pandas. It enables you to split data into groups, apply transformations, and combine results with minimal effort, making it a cornerstone of data analysis workflows in Python."
      ],
      "metadata": {
        "id": "c14nLDl4aEWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.Why is Seaborn preferred for statistical visualizations ?"
      ],
      "metadata": {
        "id": "8O57zIpOc5ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Why is Seaborn Preferred for Statistical Visualizations?\n",
        "Seaborn is a Python library built on top of Matplotlib that simplifies the creation of attractive and informative statistical visualizations. It is widely preferred for statistical data analysis due to its ease of use, high-level abstraction, and features specifically designed for visualizing complex datasets.\n",
        "\n",
        "#Key Advantages of Seaborn for Statistical Visualizations\n",
        "1.Built-in Statistical Capabilities:\n",
        "\n",
        "- Seaborn integrates statistical functionality directly into its visualization methods, such as:\n",
        "- Plotting regression lines with confidence intervals (sns.regplot()).\n",
        "- Automatically calculating and displaying distribution statistics (sns.histplot() and sns.kdeplot()).\n",
        "- This reduces the need for separate statistical libraries or manual calculations.\n",
        "\n",
        "2.Ease of Use:\n",
        "\n",
        "- Seaborn provides high-level interfaces for complex visualizations.\n",
        "- It abstracts much of the boilerplate code required in Matplotlib, making it easier to produce detailed plots with minimal effort.\n",
        "\n",
        "Example:\n",
        "\n",
        "import seaborn as sns\n",
        "sns.histplot(data=data, x='age', hue='gender', kde=True)\n",
        "A single line of code combines a histogram and kernel density estimate (KDE) plot, grouped by a categorical variable.\n",
        "\n",
        "3.Beautiful and Readable Default Styles:\n",
        "\n",
        "- Seaborn’s default styles and color palettes produce aesthetically pleasing and professional plots.\n",
        "- These styles ensure that visualizations are easy to interpret, even for non-technical audiences.\n",
        "\n",
        "4.Support for Pandas and Numpy:\n",
        "\n",
        "- Seaborn integrates seamlessly with Pandas DataFrames and Numpy arrays.\n",
        "- It allows plotting directly using DataFrame columns without needing to extract data manually.\n",
        "\n",
        "Example:\n",
        "\n",
        "import seaborn as sns\n",
        "sns.boxplot(data=df, x='category', y='value')\n",
        "\n",
        "5.Faceted and Multi-Plot Grids:\n",
        "\n",
        "- Seaborn supports creating faceted plots (subplots based on data groupings) using functions like sns.FacetGrid() or sns.catplot().\n",
        "- These are ideal for exploring relationships and patterns across multiple subsets of the data.\n",
        "Example:\n",
        "\n",
        "g = sns.FacetGrid(data=df, col='gender', row='age_group')\n",
        "g.map(sns.scatterplot, 'height', 'weight')\n",
        "\n",
        "6.Advanced Statistical Plots:\n",
        "\n",
        "- Seaborn provides functions for common statistical visualizations:\n",
        "- Correlation heatmaps (sns.heatmap()).\n",
        "- Pairwise plots (sns.pairplot()).\n",
        "- Categorical visualizations (sns.barplot(), sns.boxplot(), sns.violinplot()).\n",
        "- These functions are optimized for quick and efficient analysis of statistical patterns.\n",
        "\n",
        "7.Integration with Matplotlib:\n",
        "\n",
        "- Seaborn can be combined with Matplotlib for advanced customization.\n",
        "- Users can enhance Seaborn plots using Matplotlib’s low-level APIs if necessary.\n",
        "\n",
        "8.Built-in Color Palettes:\n",
        "\n",
        "- Seaborn offers aesthetically pleasing color palettes (sns.color_palette()), including themes for continuous and categorical data.\n",
        "- Examples: pastel, dark, colorblind, and viridis.\n",
        "\n",
        "Example:\n",
        "\n",
        "sns.set_palette('pastel')\n",
        "sns.barplot(data=df, x='category', y='value')\n",
        "\n",
        "9.Wide Range of Supported Plots:\n",
        "\n",
        "- Seaborn supports diverse plot types, such as:\n",
        "- Univariate Plots: sns.histplot(), sns.kdeplot().\n",
        "- Bivariate Plots: sns.scatterplot(), sns.regplot().\n",
        "- Categorical Plots: sns.boxplot(), sns.violinplot(), sns.stripplot().\n",
        "- Multivariate Plots: sns.pairplot(), sns.heatmap().\n",
        "\n",
        "10.Handling Complex Data Relationships:\n",
        "\n",
        "- Seaborn excels at visualizing complex relationships between variables:\n",
        "- Grouped or hierarchical data.\n",
        "- Relationships involving multiple variables simultaneously.\n",
        "\n",
        "#Seaborn vs. Matplotlib\n",
        "\n",
        "Feature\t                                                         Seaborn\t                                                             Matplotlib\n",
        "\n",
        "Focus\t                                              Statistical visualizations\t                                                    General-purpose plotting\n",
        "Ease of Use\t                                        High-level, simpler API\t                                                         Low-level, requires more code\n",
        "Default Styles\t                                    Better, more aesthetic\t                                                         Basic, requires customization\n",
        "Integration with Data\t                              Seamless with Pandas and Numpy\t                                                 Requires manual data preparation\n",
        "Statistical Features\t                              Built-in\t                                                                       Needs external libraries (e.g., SciPy)\n",
        "Customizability\t                                    Limited (extendable via Matplotlib)                                             \tHighly customizable\n",
        "\n",
        "#Conclusion\n",
        "Seaborn is preferred for statistical visualizations due to its ability to quickly and easily generate high-quality plots with integrated statistical features. Its compatibility with Pandas, intuitive API, and attractive aesthetics make it an essential tool for data analysis and visualization in Python. For tasks requiring deeper customization, Seaborn can be effectively combined with Matplotlib."
      ],
      "metadata": {
        "id": "4w3rtvVydHtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6.What are the differences between NumPy arrays and Python lists ?"
      ],
      "metadata": {
        "id": "5iX34KVQfzhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Differences Between NumPy Arrays and Python Lists\n",
        "\n",
        "NumPy arrays and Python lists are both used to store collections of data, but they have fundamental differences in terms of functionality, performance, and use cases.\n",
        "\n",
        "#Key Differences\n",
        "\n",
        "Feature\t                                        NumPy Array\t                                                            Python List\n",
        "Data Type\t                             Homogeneous (all elements must be of the same type).\t                      Heterogeneous (can store elements of different types).\n",
        "Performance\t                           Faster due to optimized C implementations.\t                                Slower due to Python's dynamic typing and general-purpose design.\n",
        "Memory Efficiency\t                     More memory-efficient for large datasets.\t                                Less efficient as each element is stored with metadata.\n",
        "Mathematical Operations\t               Supports vectorized operations (e.g., array1 + array2).\t                  Requires looping for element-wise operations.\n",
        "Dimension\t                            Supports multi-dimensional arrays (e.g., 2D, 3D).\t                          Single-dimensional; multi-dimensional structures like lists of lists are less efficient.\n",
        "Functionality\t                        Provides extensive mathematical and scientific operations.\t                Limited to basic operations; relies on external libraries for advanced tasks.\n",
        "Fixed Size\t                          Size is fixed at creation; cannot dynamically grow.\t                        Can dynamically grow or shrink as needed.\n",
        "Indexing\t                             Supports advanced indexing (e.g., slicing, masking).\t                      Basic indexing and slicing only.\n",
        "Broadcasting\t                        Allows operations between arrays of different shapes.                      \tDoes not support broadcasting.\n",
        "Dependency\t                          Requires NumPy library.                                                    \tBuilt into Python; no external dependencies.\n",
        "Usage\t                               Ideal for numerical computations and large datasets.                       \tGeneral-purpose and flexible for diverse data types.\n",
        "\n",
        "#Detailed Explanation of Key Differences\n",
        "1.Homogeneous vs. Heterogeneous Data:\n",
        "\n",
        "- NumPy Array: All elements must be of the same data type (e.g., integers, floats). This uniformity allows for faster computations and memory optimization.\n",
        "\n",
        "import numpy as np\n",
        "arr = np.array([1, 2, 3])  # Homogeneous\n",
        "\n",
        "- Python List: Can store elements of different types.\n",
        "\n",
        "lst = [1, 'two', 3.0]  # Heterogeneous\n",
        "\n",
        "2.Performance:\n",
        "\n",
        "- NumPy arrays are implemented in C and optimized for speed, making them much faster than lists, especially for numerical operations.\n",
        "\n",
        "3.Memory Efficiency:\n",
        "\n",
        "- NumPy arrays use less memory because they store only the raw data, while Python lists store additional metadata for each element (e.g., type and reference).\n",
        "\n",
        "4.Mathematical Operations:\n",
        "\n",
        "- NumPy arrays support vectorized operations, which apply an operation to all elements at once, eliminating the need for explicit loops.\n",
        "\n",
        "# NumPy Array\n",
        "arr1 = np.array([1, 2, 3])\n",
        "arr2 = np.array([4, 5, 6])\n",
        "result = arr1 + arr2  # Element-wise addition\n",
        "print(result)  # [5 7 9]\n",
        "\n",
        "- Python lists require explicit iteration for such operations:\n",
        "\n",
        "# Python List\n",
        "list1 = [1, 2, 3]\n",
        "list2 = [4, 5, 6]\n",
        "result = [x + y for x, y in zip(list1, list2)]\n",
        "print(result)  # [5, 7, 9]\n",
        "\n",
        "5.Dimension and Broadcasting:\n",
        "\n",
        "- NumPy arrays can handle multi-dimensional data and allow broadcasting to perform operations across different shapes.\n",
        "\n",
        "arr = np.array([[1, 2], [3, 4]])\n",
        "print(arr * 2)  # Multiplies each element by 2\n",
        "\n",
        "- Python lists do not support such features directly.\n",
        "\n",
        "6.Indexing:\n",
        "\n",
        "- NumPy supports advanced indexing such as boolean masking, slicing, and conditional operations.\n",
        "\n",
        "arr = np.array([10, 20, 30, 40])\n",
        "print(arr[arr > 20])  # [30 40]\n",
        "\n",
        "7.Dependency:\n",
        "\n",
        "- NumPy arrays require the NumPy library (pip install numpy), while Python lists are a built-in data structure.\n",
        "\n",
        "#When to Use NumPy Arrays vs. Python Lists?\n",
        "\n",
        "Use Case\t                                                                Preferred Choice\n",
        "Numerical or scientific computations\t                                      NumPy Array\n",
        "Large datasets requiring efficiency\t                                        NumPy Array\n",
        "General-purpose data storage\t                                              Python List\n",
        "Heterogeneous data\t                                                        Python List\n",
        "\n",
        "#Conclusion\n",
        "- NumPy arrays are specialized for numerical and scientific tasks, offering better performance, memory efficiency, and advanced functionality.\n",
        "- Python lists are more flexible and better suited for general-purpose programming with diverse data types.\n",
        "Choosing between them depends on the specific requirements of the task at hand."
      ],
      "metadata": {
        "id": "RMRux1IUgAbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. What is a heatmap, and when should it be used ?"
      ],
      "metadata": {
        "id": "PUGUtasXq48-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#What is a Heatmap?\n",
        "\n",
        "A heatmap is a data visualization technique that uses a two-dimensional graphical representation where individual values in a matrix or table are represented by colors. The intensity or variation of colors in a heatmap conveys information about the magnitude of the corresponding data values.\n",
        "\n",
        "#Characteristics of a Heatmap:\n",
        "1.Axes: Heatmaps typically have two axes (x-axis and y-axis) representing categories, variables, or features.\n",
        "2.Color Encoding: Colors represent the magnitude of data values, with a gradient or categorical scheme used to show variation.\n",
        "3.Data Representation: Heatmaps are often used to display correlations, frequencies, or any numerical data across two dimensions.\n",
        "\n",
        "#When Should a Heatmap Be Used?\n",
        "1.Analyzing Relationships Between Variables:\n",
        "\n",
        "- To identify patterns, correlations, or trends between two or more variables.\n",
        "- Example: A correlation matrix heatmap showing relationships between numerical features in a dataset.\n",
        "\n",
        "2.Visualizing Large Datasets:\n",
        "\n",
        "- To summarize large volumes of numerical data in a compact and visually interpretable format.\n",
        "\n",
        "3.Highlighting Differences or Trends:\n",
        "\n",
        "- To emphasize variations in data through contrasting colors.\n",
        "- Example: Heatmaps are often used in biology to show gene expression levels.\n",
        "\n",
        "4.Comparison Across Categories:\n",
        "\n",
        "- To compare metrics across categories or groups.\n",
        "- Example: Sales performance across regions and time periods.\n",
        "\n",
        "5.Understanding Clustering:\n",
        "\n",
        "- To visualize clusters or groups in data when paired with hierarchical clustering.\n",
        "- Example: Grouping similar customer profiles based on their purchasing behavior.\n",
        "\n",
        "#Common Use Cases of Heatmaps:\n",
        "1.Correlation Analysis:\n",
        "\n",
        "- Example: Visualizing the correlation coefficients of numerical features in a dataset.\n",
        "  - Positive correlation: Lighter shades or warm colors.\n",
        "  - Negative correlation: Darker shades or cool colors.\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Example dataset\n",
        "data = {'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Correlation matrix heatmap\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
        "plt.show()\n",
        "\n",
        "2.Geographical Heatmaps:\n",
        "\n",
        "- Representing data on a geographical map (e.g., population density or weather variations).\n",
        "\n",
        "3.Website Behavior Analysis:\n",
        "\n",
        "- Understanding user interactions by visualizing \"hot\" and \"cold\" areas of a web page.\n",
        "\n",
        "4.Performance Metrics:\n",
        "\n",
        "- Comparing metrics across teams, projects, or time periods.\n",
        "\n",
        "5.Gene Expression Studies:\n",
        "\n",
        "- Highlighting upregulated or downregulated genes in biological datasets.\n",
        "\n",
        "#Heatmap Tools and Libraries:\n",
        "1.Python Libraries:\n",
        "\n",
        "- Seaborn: For simple and beautiful heatmaps.\n",
        "- Matplotlib: For more customized heatmaps.\n",
        "- Plotly: For interactive heatmaps.\n",
        "- Pandas: Basic heatmap functionality with df.style.background_gradient().\n",
        "\n",
        "2.Excel/Spreadsheet Tools:\n",
        "\n",
        "- Use conditional formatting to create simple heatmaps for smaller datasets.\n",
        "\n",
        "#Limitations of Heatmaps:\n",
        "1.Scalability:\n",
        "\n",
        "- Large datasets with many categories can result in cluttered and unreadable heatmaps.\n",
        "\n",
        "2.Color Perception:\n",
        "\n",
        "- Misinterpretation may occur if the color gradient is not intuitive or well-defined.\n",
        "\n",
        "3.Quantitative Insight:\n",
        "\n",
        "- Heatmaps provide qualitative visualization but may lack precise quantitative details.\n",
        "\n",
        "#Conclusion\n",
        "Heatmaps are an effective way to visualize and explore relationships, patterns, and trends in numerical data. They are particularly useful when working with large datasets or when comparing multiple variables across two dimensions. Proper use of color scales, annotations, and labeling enhances their interpretability."
      ],
      "metadata": {
        "id": "muYb4WVbrGZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. What does the term “vectorized operation” mean in NumPy ?"
      ],
      "metadata": {
        "id": "EVAofSkusqvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#What Does the Term “Vectorized Operation” Mean in NumPy?\n",
        "\n",
        "A vectorized operation in NumPy refers to performing operations on entire arrays (or large chunks of data) without the need for explicit loops in Python. These operations are executed at the C-level under the hood, leveraging optimized, low-level implementations for efficiency.\n",
        "\n",
        "#Characteristics of Vectorized Operations\n",
        "1.Element-wise Execution:\n",
        "\n",
        "- The operation is applied to every element of the array automatically.\n",
        "- Example: Adding two arrays or multiplying each element by a scalar.\n",
        "\n",
        "2.No Explicit Python Loops:\n",
        "\n",
        "- Eliminates the need to iterate through elements manually.\n",
        "- This makes the code concise, easier to read, and faster.\n",
        "\n",
        "3.Leverages Optimized Libraries:\n",
        "\n",
        "- NumPy uses optimized, compiled libraries such as BLAS (Basic Linear Algebra Subprograms) and LAPACK, leading to significant performance gains.\n",
        "\n",
        "4.Broadcasting:\n",
        "\n",
        "- NumPy's broadcasting mechanism allows operations between arrays of different shapes without additional effort.\n",
        "\n",
        "#Example: Vectorized vs. Non-Vectorized Operations\n",
        "#Non-Vectorized (Using Loops)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Two lists\n",
        "list1 = [1, 2, 3]\n",
        "list2 = [4, 5, 6]\n",
        "\n",
        "# Element-wise addition using a loop\n",
        "result = []\n",
        "for x, y in zip(list1, list2):\n",
        "    result.append(x + y)\n",
        "\n",
        "print(result)  # Output: [5, 7, 9]\n",
        "\n",
        "#Vectorized (Using NumPy)\n",
        "\n",
        "# Two NumPy arrays\n",
        "arr1 = np.array([1, 2, 3])\n",
        "arr2 = np.array([4, 5, 6])\n",
        "\n",
        "# Element-wise addition\n",
        "result = arr1 + arr2\n",
        "print(result)  # Output: [5 7 9]\n",
        "\n",
        "#Benefits of Vectorized Operations\n",
        "1.Performance:\n",
        "\n",
        "- NumPy's vectorized operations are much faster than loops, especially for large datasets.\n",
        "- Loops introduce overhead because they run at the Python level, whereas vectorized operations run at the C-level.\n",
        "\n",
        "2.Readability and Conciseness:\n",
        "\n",
        "- Code is shorter and more expressive.\n",
        "- Eliminates the need for boilerplate loop structures.\n",
        "\n",
        "3.Ease of Implementation:\n",
        "\n",
        "- Complex mathematical operations can be implemented directly without manual iteration.\n",
        "\n",
        "4.Memory Efficiency:\n",
        "\n",
        "- NumPy operations are designed to be memory-efficient, often working in-place or minimizing temporary objects.\n",
        "\n",
        "#Examples of Common Vectorized Operations in NumPy\n",
        "1.Arithmetic Operations:\n",
        "\n",
        "- Element-wise addition, subtraction, multiplication, division, etc.\n",
        "\n",
        "arr = np.array([1, 2, 3])\n",
        "print(arr * 2)  # Output: [2 4 6]\n",
        "\n",
        "2.Mathematical Functions:\n",
        "\n",
        "- Apply functions like sin, cos, log, etc., to entire arrays.\n",
        "\n",
        "arr = np.array([0, np.pi/2, np.pi])\n",
        "print(np.sin(arr))  # Output: [0. 1. 0.]\n",
        "\n",
        "3.Logical Operations:\n",
        "\n",
        "- Perform comparisons element-wise.\n",
        "\n",
        "arr = np.array([1, 2, 3])\n",
        "print(arr > 1)  # Output: [False  True  True]\n",
        "\n",
        "4.Broadcasting:\n",
        "\n",
        "- Automatically expands smaller arrays to match the shape of larger arrays during operations.\n",
        "\n",
        "arr = np.array([[1, 2], [3, 4]])\n",
        "print(arr + 10)  # Output: [[11 12]\n",
        "                #          [13 14]]\n",
        "\n",
        "5.Aggregations:\n",
        "\n",
        "- Perform reductions such as sum, mean, or max.\n",
        "\n",
        "arr = np.array([1, 2, 3, 4])\n",
        "print(np.sum(arr))  # Output: 10\n",
        "\n",
        "#Key Takeaways\n",
        "- Vectorized operations eliminate the need for explicit loops, offering significant speed and efficiency gains.\n",
        "- They are central to NumPy's power, enabling high-performance computations with clean and concise code.\n",
        "- By leveraging vectorized operations, you can handle large datasets efficiently, making NumPy an essential tool for numerical and scientific computing in Python."
      ],
      "metadata": {
        "id": "hJwsp8kWtxaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9.A How does Matplotlib differ from Plotly ?"
      ],
      "metadata": {
        "id": "GyN0OnV0v0yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Differences Between Matplotlib and Plotly\n",
        "\n",
        "Both Matplotlib and Plotly are popular Python libraries for data visualization, but they serve different purposes and have distinct features. Below is a detailed comparison:\n",
        "\n",
        "#Key Differences\n",
        "\n",
        "Feature\t                            Matplotlib\t                                                                                       Plotly\n",
        "Type of Visualizations\t          Static and 2D/3D plots.\t                                                                     Interactive, web-based plots.\n",
        "Interactivity\t                    Limited interactivity (e.g., zoom, pan with tools like %matplotlib notebook).\t               Fully interactive (zoom, hover tooltips, drag, etc.).\n",
        "Ease of Use\t                      Steeper learning curve; requires more code for customization.\t                               Easier for complex, interactive plots; prebuilt themes and templates.\n",
        "Customization\t                    Highly customizable with detailed control over every aspect of the plot.\t                   Less granular customization but sufficient for most needs.\n",
        "Rendering\t                        Rendered as static images in Python environments.\t                                           Renders in web browsers using HTML and JavaScript.\n",
        "Installation\t                    Lightweight; only requires Matplotlib.\t                                                     Requires Plotly library and dependencies for browser-based rendering.\n",
        "3D Plotting\t                      Supports 3D plots (via mpl_toolkits.mplot3d) but not as feature-rich.\t                       Advanced 3D visualizations with better interactivity.\n",
        "Output Formats\t                  PNG, PDF, SVG, etc.\t                                                                         Interactive HTML files, embedded in web apps or notebooks.\n",
        "Community and Ecosystem\t          Widely used in academia and older projects; part of the SciPy ecosystem.\t                   Modern visualizations, gaining popularity in data analytics and dashboards.\n",
        "Performance\t                      Suitable for smaller datasets and basic plots.\t                                             Handles large datasets better, especially for interactive use.\n",
        "Embedding in Dashboards\t          Limited; needs additional libraries like Bokeh or Dash.\t                                     Seamlessly integrates with Dash for building dashboards.\n",
        "Animations\t                      Supported but requires manual effort and coding.\t                                           Easy and built-in support for animated plots.\n",
        "\n",
        "#Strengths of Matplotlib\n",
        "1.Static and Publication-Quality Plots:\n",
        "\n",
        "- Ideal for creating scientific or publication-ready plots.\n",
        "- Example: Research papers, reports.\n",
        "\n",
        "2.Fine-Grained Control:\n",
        "\n",
        "- Every aspect of the plot (e.g., axes, labels, colors) can be manually adjusted.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "x = [1, 2, 3]\n",
        "y = [4, 5, 6]\n",
        "plt.plot(x, y, label=\"Line Plot\")\n",
        "plt.xlabel(\"X-axis\")\n",
        "plt.ylabel(\"Y-axis\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "3.Lightweight and Fast for Small Datasets:\n",
        "\n",
        "- Suitable for environments where interactivity is not required (e.g., scripts).\n",
        "\n",
        "#Strengths of Plotly\n",
        "1.Interactivity:\n",
        "\n",
        "- Perfect for exploring data interactively, with features like zoom, hover tooltips, and clickable legends.\n",
        "\n",
        "import plotly.express as px\n",
        "df = px.data.iris()\n",
        "fig = px.scatter(df, x=\"sepal_width\", y=\"sepal_length\", color=\"species\")\n",
        "fig.show()\n",
        "\n",
        "2.Web and Dashboard Integration:\n",
        "\n",
        "- Can easily embed visualizations in web applications, notebooks, or dashboards (via Dash).\n",
        "\n",
        "3.Ease of Complex Visualizations:\n",
        "\n",
        "- Prebuilt templates and tools for creating advanced visualizations with minimal code.\n",
        "\n",
        "4.Support for Large Datasets:\n",
        "\n",
        "- Optimized for larger datasets due to its browser-based rendering.\n",
        "\n",
        "#When to Use Matplotlib vs. Plotly\n",
        "\n",
        "Use Case\t                                                                         Preferred Library\n",
        "Scientific research and static plots\t                                               Matplotlib\n",
        "Interactive exploration of data\t                                                     Plotly\n",
        "High-quality print publications\t                                                     Matplotlib\n",
        "Embedding plots in web applications\t                                                 Plotly\n",
        "Quick exploratory analysis\t                                                         Plotly (via plotly.express)\n",
        "Small datasets\t                                                                     Matplotlib\n",
        "Complex interactive dashboards\t                                                     Plotly\n",
        "\n",
        "#Conclusion\n",
        "- Matplotlib is better suited for traditional, static, and highly customizable plots, especially for academic or scientific work.\n",
        "- Plotly shines in creating interactive and modern visualizations, particularly for web-based and exploratory data analysis tasks.\n",
        "Choosing the right library depends on your project's specific requirements, including the need for interactivity, complexity, and output format."
      ],
      "metadata": {
        "id": "R26JZp3Mv9uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10.What is the significance of hierarchical indexing in Pandas ?"
      ],
      "metadata": {
        "id": "3OaXdr_ZyrIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Significance of Hierarchical Indexing in Pandas\n",
        "\n",
        "Hierarchical indexing (also known as MultiIndexing) in Pandas allows you to have multiple levels of indices on rows or columns. This feature is particularly useful when working with multi-dimensional data in a two-dimensional DataFrame or Series. It enables more powerful and flexible data manipulation, selection, and aggregation.\n",
        "\n",
        "#Key Features of Hierarchical Indexing\n",
        "1.Multiple Levels of Indexing:\n",
        "\n",
        "- Hierarchical indexing organizes data into tiers or levels, enabling multi-level representation.\n",
        "- Example: Organizing data by year and month.\n",
        "\n",
        "2.Compact Representation of Data:\n",
        "\n",
        "- MultiIndex structures save space by grouping data logically instead of repeating information.\n",
        "\n",
        "3.Facilitates Multi-Level Data Manipulation:\n",
        "\n",
        "- Simplifies operations such as aggregation, slicing, and subsetting by grouping data.\n",
        "\n",
        "4.Improved Readability:\n",
        "\n",
        "- Enhances data readability when dealing with complex datasets (e.g., cross-tabulations).\n",
        "\n",
        "#Example: MultiIndex with Rows\n",
        "Creating a MultiIndex DataFrame\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Multi-level index data\n",
        "data = {\n",
        "    'Sales': [200, 150, 300, 400],\n",
        "    'Profit': [20, 15, 30, 40]\n",
        "}\n",
        "index = [\n",
        "    ['2023', '2023', '2024', '2024'],  # Level 1: Year\n",
        "    ['Q1', 'Q2', 'Q1', 'Q2']          # Level 2: Quarter\n",
        "]\n",
        "\n",
        "# Creating MultiIndex DataFrame\n",
        "df = pd.DataFrame(data, index=pd.MultiIndex.from_tuples(zip(*index), names=['Year', 'Quarter']))\n",
        "print(df)\n",
        "\n",
        "Output:\n",
        "              Sales  Profit\n",
        "Year Quarter\n",
        "2023 Q1         200      20\n",
        "     Q2         150      15\n",
        "2024 Q1         300      30\n",
        "     Q2         400      40\n",
        "\n",
        "#Advantages of Hierarchical Indexing\n",
        "1.Advanced Data Selection:\n",
        "\n",
        "- Easily select subsets of data using one or more index levels.\n",
        "\n",
        "print(df.loc['2023'])  # Select all data for the year 2023\n",
        "print(df.loc[('2024', 'Q1')])  # Select data for 2024, Q1\n",
        "\n",
        "2.Aggregation Across Levels:\n",
        "\n",
        "- Perform operations at specific levels of the hierarchy.\n",
        "\n",
        "print(df.sum(level='Year'))  # Aggregate data by year\n",
        "\n",
        "3.Reshaping Data:\n",
        "\n",
        "- Simplifies pivoting and stacking operations.\n",
        "\n",
        "stacked = df.stack()\n",
        "print(stacked)\n",
        "\n",
        "4.Support for Complex Grouping:\n",
        "\n",
        "- Group data by multiple levels of the index.\n",
        "\n",
        "grouped = df.groupby(level='Year').sum()\n",
        "print(grouped)\n",
        "\n",
        "5.Reduced Redundancy:\n",
        "\n",
        "- Multi-level indices reduce redundancy compared to flat DataFrames.\n",
        "\n",
        "#Example: MultiIndex with Columns\n",
        "\n",
        "# MultiIndex for columns\n",
        "column_index = pd.MultiIndex.from_tuples([('Sales', '2023'), ('Sales', '2024'), ('Profit', '2023'), ('Profit', '2024')])\n",
        "data = [[200, 300, 20, 30], [150, 400, 15, 40]]\n",
        "\n",
        "df = pd.DataFrame(data, columns=column_index)\n",
        "print(df)\n",
        "\n",
        "Output:\n",
        "\n",
        "   Sales       Profit\n",
        "    2023  2024   2023  2024\n",
        "0    200   300     20    30\n",
        "1    150   400     15    40\n",
        "\n",
        "#Use Cases of Hierarchical Indexing\n",
        "1.Time-Series Data:\n",
        "\n",
        "- Organizing data by year, month, and day for detailed analysis.\n",
        "\n",
        "2.Cross-Tabulations:\n",
        "\n",
        "- Representing multi-dimensional data in a tabular format (e.g., sales by region and product).\n",
        "\n",
        "3.Grouping and Aggregation:\n",
        "\n",
        "- Grouping data by multiple features and performing aggregate calculations.\n",
        "\n",
        "4.Data Reshaping:\n",
        "\n",
        "- Converting between stacked and unstacked formats.\n",
        "\n",
        "#Conclusion\n",
        "Hierarchical indexing is a powerful feature in Pandas that simplifies the handling of multi-dimensional data in a two-dimensional structure. It allows for efficient data selection, aggregation, and manipulation while maintaining data clarity and compactness. It is particularly useful when working with datasets requiring multi-level categorization, such as time-series data, financial datasets, or grouped analyses.\n"
      ],
      "metadata": {
        "id": "AEvUmlF4yz_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11.What is the role of Seaborn’s pairplot() function ?"
      ],
      "metadata": {
        "id": "95i_KOc40y-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Role of Seaborn’s pairplot() Function\n",
        "\n",
        "Seaborn's pairplot() function is a powerful tool for visualizing relationships between multiple variables in a dataset. It creates a grid of plots, where:\n",
        "\n",
        "1.Diagonal Elements:\n",
        "\n",
        "- Typically, univariate distributions (e.g., histograms or kernel density plots) for each variable.\n",
        "\n",
        "2.Off-Diagonal Elements:\n",
        "\n",
        "- Pairwise scatter plots or other relational plots for every combination of variables.\n",
        "\n",
        "This makes pairplot() particularly useful for exploratory data analysis (EDA) when you want to understand the relationships and distribution of variables in your dataset.\n",
        "\n",
        "#Key Features of pairplot()\n",
        "1.Visualize Relationships:\n",
        "\n",
        "- Displays pairwise relationships between numeric variables in a dataset.\n",
        "\n",
        "2.Group by Categories:\n",
        "\n",
        "- Allows coloring points based on a categorical variable using the hue parameter.\n",
        "\n",
        "3.Customizable Plot Types:\n",
        "\n",
        "- Supports different kinds of plots on the diagonal (e.g., histograms or KDE plots) and off-diagonal.\n",
        "\n",
        "4.Handles Large Datasets:\n",
        "\n",
        "- Efficiently visualizes large datasets to spot trends or patterns.\n",
        "\n",
        "#Example Usage\n",
        "Basic Example\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load example dataset\n",
        "iris = sns.load_dataset(\"iris\")\n",
        "\n",
        "# Create pairplot\n",
        "sns.pairplot(iris)\n",
        "plt.show()\n",
        "\n",
        "This creates a grid of scatter plots for each pair of numeric variables in the Iris dataset, with histograms on the diagonal.\n",
        "\n",
        "#Adding a Categorical Hue\n",
        "\n",
        "sns.pairplot(iris, hue=\"species\")\n",
        "plt.show()\n",
        "\n",
        "- The points are colored by the species column, making it easy to observe how different species vary across pairs of features.\n",
        "\n",
        "#Customizing the Diagonal and Off-Diagonal Plots\n",
        "\n",
        "sns.pairplot(iris, hue=\"species\", diag_kind=\"kde\")\n",
        "plt.show()\n",
        "\n",
        "- The diagonal shows kernel density estimates (KDE) instead of histograms.\n",
        "\n",
        "#Advantages of pairplot()\n",
        "1.Quick Overview:\n",
        "\n",
        "- Provides a quick visual summary of relationships and distributions.\n",
        "\n",
        "2.Spot Patterns:\n",
        "\n",
        "- Helps identify correlations, clusters, and outliers.\n",
        "\n",
        "3.Categorical Insights:\n",
        "\n",
        "- Use of hue makes it easy to compare groups within a dataset.\n",
        "\n",
        "4.Highly Customizable:\n",
        "\n",
        "- Supports changes to aesthetics like markers, colors, and plot types.\n",
        "\n",
        "#When to Use pairplot()\n",
        "1.Exploratory Data Analysis (EDA):\n",
        "\n",
        "- Use it to explore relationships between variables in small to medium-sized datasets.\n",
        "2.Feature Selection:\n",
        "\n",
        "- Visualize correlations to identify highly related variables.\n",
        "3.Clustering or Classification Tasks:\n",
        "\n",
        "- Understand how different categories are distributed across feature pairs.\n",
        "\n",
        "#Limitations\n",
        "1.Not Suitable for Large Datasets:\n",
        "\n",
        "- Generating plots for datasets with many features or large numbers of rows can be computationally expensive.\n",
        "2.Limited to Numeric Variables:\n",
        "\n",
        "- Non-numeric columns need to be excluded or transformed.\n",
        "\n",
        "#Conclusion\n",
        "Seaborn’s pairplot() is an essential tool for visualizing pairwise relationships in a dataset. It is especially useful for small to medium datasets during the exploratory phase of analysis, allowing quick insights into relationships, trends, and clusters between variables. By leveraging the hue parameter and customizing plot types, it provides a versatile way to analyze data distributions and interactions."
      ],
      "metadata": {
        "id": "V8c7L94W0796"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#12.What is the purpose of the describe() function in Pandas ?"
      ],
      "metadata": {
        "id": "cLeftCNy2VDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Purpose of the describe() Function in Pandas\n",
        "The describe() function in Pandas is used to generate a summary of descriptive statistics for a DataFrame or Series. It provides key insights into the central tendency, dispersion, and distribution of the data. This makes it an essential tool for exploratory data analysis (EDA).\n",
        "\n",
        "#Key Features of describe()\n",
        "1.Summarizes Numeric Data:\n",
        "\n",
        "- By default, it calculates statistics such as count, mean, standard deviation, minimum, maximum, and specific percentiles (25th, 50th, 75th) for numeric columns.\n",
        "\n",
        "2.Handles Non-Numeric Data:\n",
        "\n",
        "- When applied to non-numeric columns, it provides statistics such as count, unique, top (most frequent value), and frequency of the top value.\n",
        "\n",
        "3.Customizable Scope:\n",
        "\n",
        "- Can include specific data types (numeric, categorical, all) using the include and exclude parameters.\n",
        "\n",
        "#Default Behavior\n",
        "When applied to a DataFrame with numeric columns:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Example DataFrame\n",
        "data = {\n",
        "    \"Age\": [25, 30, 35, 40, 45],\n",
        "    \"Salary\": [50000, 60000, 75000, 80000, 120000],\n",
        "    \"Experience\": [1, 3, 5, 7, 10]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Using describe()\n",
        "print(df.describe())\n",
        "\n",
        "Output:\n",
        "\n",
        "             Age         Salary  Experience\n",
        "count   5.000000      5.000000    5.000000\n",
        "mean   35.000000  77000.000000    5.200000\n",
        "std     7.905694  27166.157321    3.701351\n",
        "min    25.000000  50000.000000    1.000000\n",
        "25%    30.000000  60000.000000    3.000000\n",
        "50%    35.000000  75000.000000    5.000000\n",
        "75%    40.000000  80000.000000    7.000000\n",
        "max    45.000000 120000.000000   10.000000\n",
        "This summarizes the numeric columns of the DataFrame.\n",
        "\n",
        "#Describing Non-Numeric Data\n",
        "For categorical or object columns:\n",
        "\n",
        "data = {\n",
        "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Edward\"],\n",
        "    \"City\": [\"NY\", \"LA\", \"NY\", \"LA\", \"SF\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Describe for non-numeric data\n",
        "print(df.describe())\n",
        "\n",
        "Output:\n",
        "\n",
        "       Name City\n",
        "count     5    5\n",
        "unique    5    3\n",
        "top    Alice   NY\n",
        "freq      1    2\n",
        "\n",
        "- count: Number of non-null values.\n",
        "- unique: Number of unique values.\n",
        "- top: Most frequent value.\n",
        "- freq: Frequency of the most frequent value.\n",
        "\n",
        "#Customizing Output with include and exclude\n",
        "Include All Columns\n",
        "\n",
        "print(df.describe(include=\"all\"))\n",
        "This includes all columns (numeric and non-numeric) in the summary.\n",
        "\n",
        "#Exclude Specific Data Types\n",
        "\n",
        "print(df.describe(exclude=[\"number\"]))\n",
        "This excludes numeric columns and provides statistics for non-numeric columns only.\n",
        "\n",
        "#When to Use describe()\n",
        "1.Exploratory Data Analysis:\n",
        "\n",
        "- Quickly understand the distribution and key statistics of your dataset.\n",
        "2.Data Validation:\n",
        "\n",
        "- Verify data types, check for missing values, and validate ranges.\n",
        "3.Detect Outliers:\n",
        "\n",
        "- Spot unusual minimum, maximum, or standard deviation values.\n",
        "4.Understand Categorical Data:\n",
        "\n",
        "- Analyze frequency and cardinality of non-numeric features.\n",
        "\n",
        "#Limitations\n",
        "1.Default Behavior Focuses on Numeric Data:\n",
        "\n",
        "- Non-numeric data is ignored unless explicitly included.\n",
        "2.Limited Customization:\n",
        "\n",
        "- Cannot calculate custom statistics like mode or variance without additional coding.\n",
        "3.Large Datasets:\n",
        "\n",
        "- For large datasets, describe() can take time and might require memory optimization.\n",
        "\n",
        "#Conclusion\n",
        "The describe() function is a versatile and efficient tool for summarizing datasets in Pandas. It provides a quick snapshot of key statistical properties, enabling analysts to understand and prepare their data for further processing and modeling."
      ],
      "metadata": {
        "id": "89ZOWlZm3PwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#13.Why is handling missing data important in Pandas ?"
      ],
      "metadata": {
        "id": "O3xLTd6G5TY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Why Is Handling Missing Data Important in Pandas?\n",
        "Handling missing data in Pandas is crucial because missing values can significantly affect the accuracy, reliability, and interpretability of data analysis and machine learning models. Properly addressing missing data ensures that the dataset is prepared for meaningful insights and robust outcomes.\n",
        "\n",
        "#Key Reasons for Handling Missing Data\n",
        "1.Preserve Data Integrity:\n",
        "\n",
        "- Missing data can lead to biased results or misinterpretation of the dataset. Proper handling ensures that the data represents the underlying trends accurately.\n",
        "2.Maintain Model Performance:\n",
        "\n",
        "- Many machine learning algorithms cannot handle missing values directly and may produce errors or inaccurate predictions if missing data is present.\n",
        "3.Avoid Computational Errors:\n",
        "\n",
        "- Operations on missing data (e.g., mathematical computations) can result in runtime errors or invalid outputs.\n",
        "4.Improved Interpretability:\n",
        "\n",
        "- Understanding and addressing missing data provides clarity about the dataset's completeness and reliability.\n",
        "5.Enable Consistent Analysis:\n",
        "\n",
        "- Missing values can disrupt statistical computations like mean, standard deviation, and correlation. Filling or removing missing data ensures consistent analysis.\n",
        "6.Essential for Data Cleaning:\n",
        "\n",
        "- Handling missing values is a core step in data preprocessing, preparing the dataset for downstream tasks such as visualization or machine learning.\n",
        "\n",
        "#Common Causes of Missing Data\n",
        "1.Human Error:\n",
        "\n",
        "- Incomplete data entry or manual mistakes during data collection.\n",
        "2.Data Collection Limitations:\n",
        "\n",
        "- Missing sensor readings, skipped survey questions, or unavailable data points.\n",
        "3.Data Transformation Errors:\n",
        "\n",
        "- Issues during merging, splitting, or converting datasets.\n",
        "4.Intentional Exclusion:\n",
        "\n",
        "- Certain data might not be recorded due to irrelevance or privacy concerns.\n",
        "\n",
        "#Approaches to Handle Missing Data in Pandas\n",
        "1.Identify Missing Data:\n",
        "\n",
        "- Use functions like isnull() or info() to detect missing values.\n",
        "\n",
        "df.isnull().sum()  # Count missing values in each column\n",
        "\n",
        "2.Drop Missing Data:\n",
        "\n",
        "- Remove rows or columns with missing values using dropna().\n",
        "\n",
        "df.dropna(inplace=True)  # Drop rows with missing values\n",
        "\n",
        "3.Fill Missing Data:\n",
        "\n",
        "- Fill missing values using fillna() with appropriate strategies:\n",
        "  - Constant Value:\n",
        "\n",
        "df.fillna(0, inplace=True)  # Replace NaNs with 0\n",
        "  - Forward/Backward Fill:\n",
        "\n",
        "df.fillna(method='ffill', inplace=True)  # Fill with previous value\n",
        "  - Statistical Imputation:\n",
        "\n",
        "df['column'].fillna(df['column'].mean(), inplace=True)  # Fill with mean\n",
        "\n",
        "4.Interpolate Missing Values:\n",
        "\n",
        "- Estimate missing values using interpolation techniques.\n",
        "\n",
        "df.interpolate(method='linear', inplace=True)\n",
        "\n",
        "5.Flag Missing Data:\n",
        "\n",
        "- Create a new column indicating whether a value was missing.\n",
        "\n",
        "df['missing_flag'] = df['column'].isnull()\n",
        "\n",
        "6.Replace Missing Data Based on Domain Knowledge:\n",
        "\n",
        "- Use knowledge about the dataset to replace missing values with meaningful substitutes.\n",
        "\n",
        "#Consequences of Ignoring Missing Data\n",
        "1.Loss of Insights:\n",
        "\n",
        "- Key patterns or relationships may be hidden or distorted.\n",
        "2.Bias in Analysis:\n",
        "\n",
        "- Ignoring missing data can skew the analysis, leading to incorrect conclusions.\n",
        "3.Errors in Machine Learning Models:\n",
        "\n",
        "- Missing data may cause training or prediction errors, resulting in poor model performance.\n",
        "4.Data Loss:\n",
        "\n",
        "- Simply dropping rows or columns can lead to significant loss of information, especially in datasets with a high proportion of missing values.\n",
        "\n",
        "#Best Practices\n",
        "1.Understand the Nature of Missing Data:\n",
        "\n",
        "- Determine if missingness is random, systematic, or related to specific factors.\n",
        "2.Document Handling Decisions:\n",
        "\n",
        "- Clearly record how missing data was handled to ensure reproducibility.\n",
        "3.Use Domain Knowledge:\n",
        "\n",
        "- Leverage context to make informed decisions about imputation or removal.\n",
        "4.Test Different Strategies:\n",
        "\n",
        "- Evaluate the impact of different handling methods on your analysis or model performance.\n",
        "\n",
        "#Conclusion\n",
        "Handling missing data in Pandas is critical for ensuring data quality and the reliability of insights. By carefully identifying and addressing missing values using appropriate strategies, you can minimize biases, avoid computational errors, and prepare the dataset for effective analysis and modeling. Proper handling of missing data lays the foundation for trustworthy and accurate data-driven decision-making."
      ],
      "metadata": {
        "id": "B2vZ7PLc5anF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#14.What are the benefits of using Plotly for data visualization ?"
      ],
      "metadata": {
        "id": "Q1GoA0607YdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Benefits of Using Plotly for Data Visualization\n",
        "Plotly is a popular Python library for creating interactive, high-quality, and aesthetically pleasing data visualizations. It stands out from other libraries due to its flexibility, ease of use, and ability to produce both simple and complex visualizations. Here are the key benefits of using Plotly for data visualization:\n",
        "\n",
        "1. Interactivity\n",
        "- Dynamic Visualizations: Plotly enables the creation of interactive plots where users can zoom, pan, hover over data points, and filter data dynamically.\n",
        "- User Engagement: Interactivity makes visualizations more engaging and allows users to explore data in greater depth.\n",
        "2. High-Quality Aesthetics\n",
        "- Professional Appearance: Plotly produces visually appealing and publication-quality graphs by default.\n",
        "- Customizable Styling: Almost every aspect of the chart (colors, fonts, sizes, etc.) can be customized to match specific design requirements.\n",
        "3. Wide Range of Chart Types\n",
        "- Plotly supports a vast array of chart types, including:\n",
        "\n",
        "- Basic Plots: Line, bar, scatter, pie, and histogram charts.\n",
        "- Advanced Visualizations: 3D plots, heatmaps, candlestick charts, sunburst charts, and choropleth maps.\n",
        "- Statistical and Scientific Plots: Box plots, violin plots, and contour plots.\n",
        "4. Cross-Platform and Embeddable\n",
        "- Web-Based Visualizations: Plotly generates visualizations in HTML, making them embeddable in web applications, dashboards, and reports.\n",
        "- Multi-Platform Support: Works seamlessly in Jupyter Notebooks, standalone scripts, or web frameworks like Dash.\n",
        "- Sharing: Easy to share interactive visualizations via URLs or as standalone HTML files.\n",
        "5. Integration with Dash\n",
        "- Dash Applications: Plotly integrates with Dash, a Python framework for building interactive web applications. This allows users to combine visualizations with interactive controls (e.g., dropdowns, sliders) for data exploration.\n",
        "6. Compatibility with Other Libraries\n",
        "- Plotly works well with:\n",
        "- Pandas: Simplifies the process of creating plots directly from DataFrames.\n",
        "- NumPy and SciPy: Supports numerical and scientific data.\n",
        "- Other Visualization Libraries: Can complement tools like Matplotlib and Seaborn.\n",
        "7. 3D Plotting Capabilities\n",
        "- Plotly provides robust support for 3D visualizations, such as 3D scatter plots, surface plots, and volumetric visualizations, making it suitable for scientific and engineering applications.\n",
        "8. Cross-Language Support\n",
        "- Multi-Language API: Plotly can be used not only in Python but also in R, MATLAB, Julia, and JavaScript, providing flexibility across different programming environments.\n",
        "9. Built-In Hover and Tooltip Features\n",
        "- Plotly automatically adds tooltips to display data details on hover, which enhances usability without requiring additional coding.\n",
        "10. Accessibility\n",
        "- Responsive Design: Visualizations created with Plotly are responsive, making them suitable for devices of varying screen sizes.\n",
        "- Accessibility Features: Interactive elements improve accessibility for users who want to explore data visually.\n",
        "11. Community and Documentation\n",
        "- Active Community: Plotly has a strong user community, providing ample support, examples, and solutions for common problems.\n",
        "- Comprehensive Documentation: Well-documented API with examples and tutorials for beginners and advanced users.\n",
        "12. Free and Open Source\n",
        "- Free Version: The core functionality of Plotly is open-source and free to use.\n",
        "- Enterprise Options: Offers advanced features for enterprise users who need additional support or secure data sharing.\n",
        "\n",
        "#Use Cases for Plotly\n",
        "1.Exploratory Data Analysis (EDA):\n",
        "- Interactive charts help analysts explore relationships and patterns in the data.\n",
        "2.Dashboards:\n",
        "- Plotly visualizations can be integrated into web-based dashboards using Dash.\n",
        "3.Scientific Research:\n",
        "- Suitable for plotting complex scientific or engineering data.\n",
        "4.Business Presentations:\n",
        "- High-quality visuals enhance communication in reports and presentations.\n",
        "5.Geospatial Analysis:\n",
        "- Create choropleth maps, scatter maps, and other geographical visualizations.\n",
        "\n",
        "#Comparison with Other Libraries\n",
        "\n",
        "Feature\t                                                       Plotly\t                                     Matplotlib\t                                      Seaborn\n",
        "\n",
        "Interactivity\t                                                  Yes\t                                          No\t                                            Limited\n",
        "Aesthetics\t                                                High-quality out of the box\t                Requires tweaking\t                                     Good\n",
        "Chart Variety\t                                                Extensive\t                                  Moderate\t                                          Moderate\n",
        "3D Support\t                                                     Yes\t                                    Limited\t                                               No\n",
        "Integration\t                                                      Dash, Web, Jupyter\t                    Jupyter\t                                             Jupyter\n",
        "\n",
        "#Conclusion\n",
        "Plotly’s interactivity, aesthetic appeal, and wide range of features make it an excellent choice for data visualization. It is particularly suited for scenarios requiring dynamic exploration, high-quality visuals, or web-based applications. Whether you're conducting exploratory analysis, building dashboards, or sharing insights with stakeholders, Plotly is a powerful and versatile tool to include in your data science toolkit."
      ],
      "metadata": {
        "id": "OOteqVXU7i-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#15. How does NumPy handle multidimensional arrays ?"
      ],
      "metadata": {
        "id": "1-tR2yeU-K1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#How Does NumPy Handle Multidimensional Arrays?\n",
        "NumPy is designed to handle multidimensional arrays efficiently, providing powerful tools for creating, manipulating, and performing computations on them. These arrays, called ndarrays, are at the core of NumPy and support operations that are optimized for performance.\n",
        "\n",
        "#Key Features of NumPy Multidimensional Arrays\n",
        "1.Flexible Dimensions (ndim):\n",
        "\n",
        "- NumPy arrays can have any number of dimensions.\n",
        "- A 1D array represents a vector, a 2D array represents a matrix, and higher dimensions are represented as tensors.\n",
        "2.Efficient Storage (shape):\n",
        "\n",
        "- The shape attribute of an array describes its dimensions as a tuple of integers.\n",
        "\n",
        "import numpy as np\n",
        "array = np.array([[1, 2], [3, 4]])\n",
        "print(array.shape)  # Output: (2, 2)\n",
        "3.Homogeneous Data Type (dtype):\n",
        "\n",
        "- All elements in a NumPy array must have the same data type, which ensures efficient memory use and fast computations.\n",
        "4.Arbitrary Dimensions:\n",
        "\n",
        "- You can create arrays with more than two dimensions:\n",
        "\n",
        "array_3d = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
        "print(array_3d.shape)  # Output: (2, 2, 2)\n",
        "\n",
        "#Creating Multidimensional Arrays\n",
        "1.From Lists or Nested Lists:\n",
        "\n",
        "array_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "2.Using Built-In Functions:\n",
        "\n",
        "- Zeros:\n",
        "\n",
        "np.zeros((3, 4))  # Creates a 3x4 array filled with zeros\n",
        "- Ones:\n",
        "\n",
        "np.ones((2, 2, 2))  # Creates a 2x2x2 array filled with ones\n",
        "- Random Values:\n",
        "\n",
        "np.random.rand(4, 4)  # Creates a 4x4 array with random values\n",
        "3.Using arange and reshape:\n",
        "\n",
        "array = np.arange(12).reshape(3, 4)\n",
        "print(array)\n",
        "# Output:\n",
        "# [[ 0  1  2  3]\n",
        "#  [ 4  5  6  7]\n",
        "#  [ 8  9 10 11]]\n",
        "\n",
        "#Indexing and Slicing\n",
        "1.Indexing:\n",
        "\n",
        "- Access specific elements using indices.\n",
        "\n",
        "array = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "print(array[0, 1])  # Output: 2\n",
        "\n",
        "2.Slicing:\n",
        "\n",
        "- Extract subarrays using slices.\n",
        "\n",
        "print(array[:, 1])  # Output: [2 5]\n",
        "\n",
        "3.Multidimensional Indexing:\n",
        "\n",
        "- You can combine slicing and indexing for multidimensional arrays.\n",
        "\n",
        "print(array[1, :2])  # Output: [4 5]\n",
        "\n",
        "#Broadcasting\n",
        "NumPy supports broadcasting, a mechanism for performing operations on arrays with different shapes:\n",
        "\n",
        "- Smaller arrays are automatically \"expanded\" to match the dimensions of larger arrays during operations.\n",
        "\n",
        "array = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "result = array + 10  # Broadcast scalar 10 across all elements\n",
        "print(result)\n",
        "# Output:\n",
        "# [[11 12 13]\n",
        "#  [14 15 16]]\n",
        "\n",
        "#Vectorized Operations\n",
        "- Operations on arrays are applied element-wise, eliminating the need for explicit loops.\n",
        "\n",
        "array = np.array([[1, 2], [3, 4]])\n",
        "print(array * 2)\n",
        "# Output:\n",
        "# [[2 4]\n",
        "#  [6 8]]\n",
        "\n",
        "#Advanced Operations\n",
        "1.Aggregation:\n",
        "\n",
        "- Compute summaries like sum, mean, or max along specific axes.\n",
        "\n",
        "array = np.array([[1, 2], [3, 4]])\n",
        "print(array.sum(axis=0))  # Output: [4 6] (column-wise sum)\n",
        "2.Transposition:\n",
        "\n",
        "- Change the orientation of an array using T.\n",
        "\n",
        "print(array.T)\n",
        "# Output:\n",
        "# [[1 3]\n",
        "#  [2 4]]\n",
        "3.Reshaping:\n",
        "\n",
        "- Change the dimensions without modifying data using reshape.\n",
        "\n",
        "reshaped = array.reshape(4, 1)\n",
        "4.Concatenation:\n",
        "\n",
        "- Combine arrays along specified axes.\n",
        "\n",
        "np.concatenate([array, array], axis=1)\n",
        "5.Boolean Masking:\n",
        "\n",
        "- Filter elements using conditions.\n",
        "\n",
        "print(array[array > 2])\n",
        "# Output: [3 4]\n",
        "\n",
        "#Performance and Memory Efficiency\n",
        "1.Efficient Storage:\n",
        "\n",
        "- Multidimensional arrays are stored in contiguous memory blocks, ensuring fast access and processing.\n",
        "2.Low Memory Overhead:\n",
        "\n",
        "- NumPy arrays consume less memory than equivalent Python lists due to their homogeneous data type and optimized storage.\n",
        "3.C-Backend Optimization:\n",
        "\n",
        "- NumPy is implemented in C, providing fast computation speeds even for large datasets.\n",
        "\n",
        "#Conclusion\n",
        "NumPy handles multidimensional arrays with unparalleled flexibility and performance, making it a cornerstone of numerical and scientific computing in Python. Its capabilities—such as efficient storage, slicing, broadcasting, and vectorized operations—enable users to work seamlessly with data of any shape and size, ensuring both speed and simplicity."
      ],
      "metadata": {
        "id": "ty0amGU--Scw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#16.What is the role of Bokeh in data visualization ?"
      ],
      "metadata": {
        "id": "X3zhHYTxA1Pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Role of Bokeh in Data Visualization\n",
        "Bokeh is a powerful, interactive data visualization library for Python that enables the creation of sophisticated visualizations for both web-based and offline environments. Its primary strength lies in its ability to generate interactive plots with minimal effort, making it an excellent tool for data exploration and dashboard creation. Bokeh supports a wide range of plotting capabilities and integrates well with other tools and frameworks like Jupyter Notebooks and Flask.\n",
        "\n",
        "#Key Features and Role of Bokeh in Data Visualization\n",
        "1.Interactive Visualizations:\n",
        "\n",
        "- Bokeh allows you to create plots that are highly interactive. Users can zoom, pan, hover over points to see tooltips, and even select or filter data dynamically.\n",
        "- This interactivity is crucial for data exploration, enabling users to engage with the data and gain deeper insights in a more intuitive way.\n",
        "2.Web-Ready Plots:\n",
        "\n",
        "- Bokeh visualizations are rendered as HTML and JavaScript, making them ideal for embedding into web applications, dashboards, and interactive reports.\n",
        "- Plots can be embedded directly into websites, making Bokeh a great choice for creating interactive, web-based data visualizations.\n",
        "3.Ease of Use:\n",
        "\n",
        "- Bokeh provides a simple and intuitive API that allows users to quickly generate complex plots with minimal coding. It is especially user-friendly for those who want to create dynamic visualizations without needing deep knowledge of web technologies.\n",
        "- It includes tools for customizing every aspect of a plot, from axes and labels to tooltips and interaction methods.\n",
        "4.Integration with Other Libraries:\n",
        "\n",
        "- Bokeh can be easily integrated with popular Python libraries like Pandas (for working with data), NumPy (for numerical operations), and Matplotlib (for static plots).\n",
        "- It also integrates well with Jupyter Notebooks for creating inline interactive visualizations and with Flask or Django for deploying interactive plots on web servers.\n",
        "5.Wide Variety of Plot Types:\n",
        "\n",
        "- Bokeh supports a wide array of plot types, such as:\n",
        "- Basic Plots: Line, bar, scatter, and pie charts.\n",
        "- Statistical Plots: Histograms, box plots, and heatmaps.\n",
        "- Geospatial Plots: Geospatial visualizations such as choropleth maps and scatter maps.\n",
        "- 3D Plots: 3D scatter plots and surface plots (via integration with other libraries like plotly).\n",
        "- Complex Plots: Network diagrams, stream graphs, and timelines.\n",
        "6.Customizability and Flexibility:\n",
        "\n",
        "- Bokeh allows you to customize almost every aspect of the plot, including colors, tooltips, axes, gridlines, legends, and more. This flexibility makes it an ideal choice for creating polished and highly tailored visualizations.\n",
        "- You can also build interactive widgets (like sliders, dropdowns, and buttons) that allow users to control various aspects of the plot.\n",
        "7.Efficient Handling of Large Datasets:\n",
        "\n",
        "- Bokeh is optimized for handling large datasets with interactive features. It uses a client-server architecture, enabling large datasets to be visualized efficiently even in the web environment.\n",
        "- The plots can be streamed and updated dynamically, making them suitable for applications that require real-time data visualization.\n",
        "8.Real-Time Data Streaming:\n",
        "\n",
        "- Bokeh allows real-time data streaming into plots, which is useful for applications like monitoring dashboards, financial data visualization, or live data analytics.\n",
        "- It can update the plot in real-time without the need for refreshing the entire page.\n",
        "\n",
        "#Comparison with Other Data Visualization Libraries\n",
        "\n",
        "Feature\t                           Bokeh\t                                                 Matplotlib\t                                   Plotly\n",
        "\n",
        "Interactivity\t              Highly interactive (zoom, pan, tooltips)\t                 Limited (static)\t                       Highly interactive (zoom, hover, filter)\n",
        "Ease of Use\t                Easy to learn and implement\t                               Steeper learning curve\t                  Easy to use and highly intuitive\n",
        "Integration with Web\t      Excellent (HTML, JS output)\t                                 Limited\t                                Excellent (HTML, JS output)\n",
        "Real-Time Streaming\t        Supports real-time streaming\t                            Not ideal for real-time\t                   Supports real-time updates\n",
        "Customization\t              High (many interactive features)\t                        Moderate (static customizations)\t          High (customizable charts)\n",
        "Plot Types\t                Wide range (basic to complex)\t                            Wide range (static plots)\t                  Wide range (static and interactive)\n",
        "3D Plotting\t                Limited support\t                                          Limited support\t                             Strong 3D support\n",
        "\n",
        "#Use Cases for Bokeh\n",
        "1.Web-Based Dashboards:\n",
        "\n",
        "- Bokeh is commonly used to build interactive dashboards for web applications. It integrates seamlessly with web frameworks like Flask and Django, allowing developers to create custom dashboards with real-time data.\n",
        "2.Exploratory Data Analysis (EDA):\n",
        "\n",
        "- During EDA, interactivity helps analysts explore relationships between different features in a dataset and visualize complex data patterns.\n",
        "3.Business Intelligence:\n",
        "\n",
        "- Data-driven decision-making often requires interactive, real-time visualizations. Bokeh is widely used to build live dashboards for monitoring KPIs, financial data, and other business metrics.\n",
        "4.Geospatial Data Visualization:\n",
        "\n",
        "- Bokeh can be used to create interactive maps, making it suitable for geospatial analysis, such as visualizing geographic trends, clustering, and spatial distributions.\n",
        "5.Scientific Visualization:\n",
        "\n",
        "- Scientists and researchers use Bokeh to visualize complex datasets, such as time-series data, experimental results, and statistical distributions, with interactive features to explore trends in detail.\n",
        "\n",
        "#Example of Creating a Simple Interactive Plot in Bokeh\n",
        "\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.models import ColumnDataSource\n",
        "\n",
        "# Create some data\n",
        "data = {'x': [1, 2, 3, 4, 5], 'y': [6, 7, 2, 4, 5]}\n",
        "source = ColumnDataSource(data)\n",
        "\n",
        "# Create a new plot\n",
        "p = figure(title=\"Interactive Plot Example\", x_axis_label='X-Axis', y_axis_label='Y-Axis')\n",
        "\n",
        "# Add a scatter plot\n",
        "p.scatter(x='x', y='y', size=8, color=\"red\", alpha=0.6, source=source)\n",
        "\n",
        "# Show the plot\n",
        "show(p)\n",
        "\n",
        "In this example, a simple interactive scatter plot is created using Bokeh. The plot supports zooming, panning, and tooltips to provide more details about the data points.\n",
        "\n",
        "#Conclusion\n",
        "Bokeh plays a vital role in interactive data visualization by providing powerful tools to create real-time, web-based, and highly customizable visualizations. Its focus on interactivity, ease of use, and seamless integration with web frameworks makes it an excellent choice for data scientists, analysts, and developers who need to create engaging and interactive visualizations for complex datasets. Whether for exploratory data analysis, business intelligence dashboards, or scientific research, Bokeh enables users to create stunning and insightful visual representations of their data."
      ],
      "metadata": {
        "id": "cYuiK2WQBAWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#17. Explain the difference between apply() and map() in Pandas ?"
      ],
      "metadata": {
        "id": "4EnVo68bDb_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Difference Between apply() and map() in Pandas\n",
        "Both apply() and map() are powerful functions in Pandas that are used for applying functions to data structures like Series and DataFrames. However, they differ in their usage, functionality, and performance. Let's break down each method:\n",
        "\n",
        "1. map() Function\n",
        "- Used For: The map() function is used for element-wise transformations on a Pandas Series. It can be used to apply a function to each element in the Series.\n",
        "- Works on: It works only on a single column (Series), not on DataFrames.\n",
        "- Functionality:\n",
        "  - It can apply a function, a dictionary, or a Series to each element.\n",
        "  - If a dictionary or Series is passed, it maps the value based on matching keys or indices.\n",
        "- Return Type: It returns a new Series where each element is the result of applying the function.\n",
        "\n",
        "#Example 1: Using map() with a function\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.Series([1, 2, 3, 4, 5])\n",
        "\n",
        "# Applying a function to each element\n",
        "squared = data.map(lambda x: x ** 2)\n",
        "print(squared)\n",
        "\n",
        "Output:\n",
        "\n",
        "0     1\n",
        "1     4\n",
        "2     9\n",
        "3    16\n",
        "4    25\n",
        "dtype: int64\n",
        "#Example 2: Using map() with a dictionary\n",
        "\n",
        "data = pd.Series(['cat', 'dog', 'rabbit'])\n",
        "\n",
        "# Mapping each animal to its sound\n",
        "sounds = {'cat': 'meow', 'dog': 'bark'}\n",
        "mapped = data.map(sounds)\n",
        "print(mapped)\n",
        "\n",
        "Output:\n",
        "\n",
        "0     meow\n",
        "1     bark\n",
        "2     NaN\n",
        "dtype: object\n",
        "- In this case, 'rabbit' does not exist in the dictionary, so it returns NaN for that value.\n",
        "\n",
        "2. apply() Function\n",
        "- Used For: The apply() function can be used to apply a function along the axis of a DataFrame (rows or columns) or on a Pandas Series.\n",
        "- Works on: It works on both Series and DataFrames. It can be applied to individual columns (Series) or to entire DataFrames (across rows or columns).\n",
        "- Functionality:\n",
        "  - For Series, it applies the function element-wise, similar to map().\n",
        "  - For DataFrames, it applies the function along a specified axis (either rows or columns).\n",
        "- Return Type: The result returned by apply() can vary depending on the function applied (e.g., Series, DataFrame, or scalar).\n",
        "#Example 1: Using apply() on a Series\n",
        "\n",
        "data = pd.Series([1, 2, 3, 4, 5])\n",
        "\n",
        "# Applying a function element-wise\n",
        "squared = data.apply(lambda x: x ** 2)\n",
        "print(squared)\n",
        "\n",
        "Output:\n",
        "\n",
        "0     1\n",
        "1     4\n",
        "2     9\n",
        "3    16\n",
        "4    25\n",
        "dtype: int64\n",
        "#Example 2: Using apply() on a DataFrame (along rows)\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    'A': [1, 2, 3],\n",
        "    'B': [4, 5, 6]\n",
        "})\n",
        "\n",
        "# Applying a function along rows (axis=1)\n",
        "result = data.apply(lambda row: row['A'] + row['B'], axis=1)\n",
        "print(result)\n",
        "\n",
        "Output:\n",
        "\n",
        "0    5\n",
        "1    7\n",
        "2    9\n",
        "dtype: int64\n",
        "#Example 3: Using apply() on a DataFrame (along columns)\n",
        "\n",
        "result = data.apply(lambda col: col.max(), axis=0)  # Axis 0 refers to columns\n",
        "print(result)\n",
        "\n",
        "Output:\n",
        "\n",
        "A    3\n",
        "B    6\n",
        "dtype: int64\n",
        "\n",
        "#Key Differences Between apply() and map()\n",
        "\n",
        "Feature\t                         map()\t                                            apply()\n",
        "Works on\t                Pandas Series only\t                                 Pandas Series and DataFrame\n",
        "Element-wise\t            Yes, applies a function to each element\t             Yes (Series) or applies function along axis (DataFrame)\n",
        "Function Type\t            Function, dictionary, or Series mapping\t             Function (applied across rows/columns)\n",
        "Performance\t             Faster for element-wise operations on Series\t         Slightly slower due to flexibility (works with DataFrames)\n",
        "Use Case\t                Simple, element-wise transformations\t               More complex transformations, including row/column-based operations in DataFrames\n",
        "Return Type\t               Series\t                                               Series, DataFrame, or scalar\n",
        "\n",
        "#Summary\n",
        "- Use map() when you need to perform simple, element-wise operations on a Series and when you might want to map values based on a dictionary or Series.\n",
        "- Use apply() when you need more flexibility, such as applying a function to the entire DataFrame (across rows or columns), or when you need to apply complex functions to a Series.\n",
        "In general, apply() is more versatile and flexible, while map() is simpler and better for straightforward element-wise transformations on Series."
      ],
      "metadata": {
        "id": "CgYXFwLLDmQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#18.What are some advanced features of NumPy ?"
      ],
      "metadata": {
        "id": "n5m8jsIhF0zN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NumPy is a powerful library for numerical computations in Python, and it offers several advanced features that enhance its performance, flexibility, and usability. Below are some of the advanced features of NumPy:\n",
        "\n",
        "1. Broadcasting\n",
        "- Definition: Broadcasting allows NumPy to perform element-wise operations on arrays of different shapes and sizes. It automatically expands the dimensions of smaller arrays to match the larger array without copying data, which makes it both efficient and memory-friendly.\n",
        "- Example: Adding a scalar to an array or performing operations between arrays of different shapes.\n",
        "\n",
        "import numpy as np\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([10])\n",
        "result = a + b  # Broadcasting the scalar b to match the shape of a\n",
        "print(result)  # Output: [11 12 13]\n",
        "\n",
        "2. Vectorization\n",
        "- Definition: Vectorization refers to the ability of NumPy to perform operations on entire arrays or matrices at once, rather than using explicit loops. This leads to faster execution because operations are implemented in compiled C code, making them more efficient than native Python loops.\n",
        "- Example: Perform element-wise arithmetic on arrays without loops.\n",
        "\n",
        "a = np.array([1, 2, 3, 4])\n",
        "b = np.array([10, 20, 30, 40])\n",
        "result = a + b  # Element-wise addition without loops\n",
        "print(result)  # Output: [11 22 33 44]\n",
        "\n",
        "3. Fancy Indexing and Slicing\n",
        "- Definition: NumPy allows you to index arrays using another array or list of indices, which can be very powerful for selecting or modifying array elements.\n",
        "- Example: Using a list of indices or boolean indexing to retrieve or modify array values.\n",
        "\n",
        "arr = np.array([10, 20, 30, 40, 50])\n",
        "indices = [0, 2, 4]\n",
        "print(arr[indices])  # Output: [10 30 50]\n",
        "\n",
        "# Boolean indexing\n",
        "condition = arr > 30\n",
        "print(arr[condition])  # Output: [40 50]\n",
        "\n",
        "4. Memory Views and Strides\n",
        "- Definition: NumPy allows you to work with \"views\" of arrays, where you can access and manipulate data without copying it. This is especially useful when working with large datasets, as it saves both time and memory.\n",
        "- Strides specify how many bytes you need to step in each dimension when traversing an array.\n",
        "- Example: Using .view() and .reshape() to create memory-efficient views of arrays.\n",
        "\n",
        "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "view = arr[:, 1]  # Creating a view of the second column\n",
        "print(view)  # Output: [2 5]\n",
        "\n",
        "# Using strides to view a subarray\n",
        "subarray = arr.strides\n",
        "print(subarray)  # Output: (12, 4) (bytes per dimension)\n",
        "\n",
        "5. Linear Algebra Operations\n",
        "- Definition: NumPy provides a rich set of functions for linear algebra operations, such as matrix multiplication, dot products, eigenvalue decomposition, solving systems of linear equations, etc.\n",
        "- Example: Matrix multiplication using np.dot() and np.matmul().\n",
        "\n",
        "A = np.array([[1, 2], [3, 4]])\n",
        "B = np.array([[5, 6], [7, 8]])\n",
        "result = np.dot(A, B)  # Matrix multiplication\n",
        "print(result)\n",
        "\n",
        "6. Random Number Generation\n",
        "- Definition: The numpy.random module provides a variety of functions to generate random numbers and samples, including random arrays, permutations, and distributions like normal, binomial, and Poisson.\n",
        "- Example: Generating random numbers, selecting random elements, and generating random distributions.\n",
        "\n",
        "# Random integers between 0 and 9\n",
        "random_integers = np.random.randint(0, 10, size=(2, 3))\n",
        "print(random_integers)\n",
        "\n",
        "# Random sample from a normal distribution\n",
        "normal_sample = np.random.normal(loc=0, scale=1, size=10)\n",
        "print(normal_sample)\n",
        "\n",
        "7. Multi-dimensional Array Manipulation\n",
        "- Definition: NumPy allows manipulation of arrays with more than one dimension, including reshaping, stacking, splitting, and transposing.\n",
        "- Example: Changing the shape of an array or performing operations on multi-dimensional arrays.\n",
        "\n",
        "# Reshape an array\n",
        "arr = np.array([1, 2, 3, 4, 5, 6])\n",
        "reshaped = arr.reshape(2, 3)\n",
        "print(reshaped)\n",
        "\n",
        "# Transpose a matrix\n",
        "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "transposed = matrix.T\n",
        "print(transposed)\n",
        "\n",
        "8. Advanced Statistical Functions\n",
        "- Definition: NumPy provides a wide range of functions for performing advanced statistical analysis, such as calculating means, variances, standard deviations, correlation, and more.\n",
        "- Example: Computing statistical measures and other advanced functions.\n",
        "\n",
        "arr = np.array([1, 2, 3, 4, 5])\n",
        "mean = np.mean(arr)\n",
        "std_dev = np.std(arr)\n",
        "print(f'Mean: {mean}, Standard Deviation: {std_dev}')\n",
        "\n",
        "9. Element-wise Mathematical Functions\n",
        "- Definition: NumPy includes a set of functions for element-wise operations like sin(), cos(), log(), and other mathematical operations. These functions work on entire arrays, providing optimized performance.\n",
        "- Example: Applying mathematical operations to entire arrays.\n",
        "\n",
        "arr = np.array([0, np.pi/2, np.pi])\n",
        "sine_values = np.sin(arr)\n",
        "print(sine_values)  # Output: [0. 1. 0.]\n",
        "\n",
        "10. Masked Arrays\n",
        "- Definition: NumPy provides masked arrays for dealing with arrays that have missing or invalid data. Masked arrays allow you to mark specific elements as invalid and then ignore them in calculations.\n",
        "- Example: Using np.ma.masked to create a masked array.\n",
        "\n",
        "arr = np.array([1, 2, 3, 4, 5])\n",
        "masked_arr = np.ma.masked_array(arr, mask=[0, 1, 0, 0, 1])\n",
        "print(masked_arr)  # Output: [-- 2 -- 4 --]\n",
        "\n",
        "11. Memory Management and Efficient Computation\n",
        "- Definition: NumPy provides tools to manage memory efficiently when working with large datasets, including memory-mapped arrays and in-place operations to avoid creating unnecessary copies of data.\n",
        "- Example: Memory-mapped arrays are useful when working with data too large to fit into memory.\n",
        "\n",
        "# Memory-mapping a large binary file to an array\n",
        "filename = 'large_data.dat'\n",
        "large_array = np.memmap(filename, dtype='float32', mode='r', shape=(10000, 10000))\n",
        "\n",
        "12. Custom UFuncs (Universal Functions)\n",
        "- Definition: NumPy allows you to define your own custom universal functions (ufuncs). These are functions that can operate on arrays element-wise, just like the built-in ufuncs.\n",
        "- Example: Defining a custom ufunc.\n",
        "\n",
        "def custom_func(x):\n",
        "    return x**2 + 2*x + 1\n",
        "\n",
        "custom_ufunc = np.frompyfunc(custom_func, 1, 1)\n",
        "result = custom_ufunc(np.array([1, 2, 3]))\n",
        "print(result)\n",
        "\n",
        "#Summary\n",
        "NumPy offers a wide range of advanced features that make it suitable for performing high-performance numerical computations in Python. These features include broadcasting, vectorization, advanced indexing, linear algebra operations, random number generation, multi-dimensional array manipulation, and statistical functions. With NumPy's ability to handle large datasets efficiently and support for memory management and custom functions, it remains an essential tool for data scientists and engineers working with numerical and scientific data."
      ],
      "metadata": {
        "id": "0wQr68yuF93W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#19.How does Pandas simplify time series analysis ?"
      ],
      "metadata": {
        "id": "bjE83QbvLCnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Pandas provides powerful tools and functionalities that simplify time series analysis, making it easier to manage, analyze, and manipulate time-based data. Here's how Pandas facilitates time series analysis:\n",
        "\n",
        "1. Datetime Indexing\n",
        "- Pandas allows the use of DatetimeIndex to index data by time, enabling efficient slicing and subsetting of data based on time ranges.\n",
        "- Example: Slicing data for a specific month or year.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Creating a time series with a DatetimeIndex\n",
        "dates = pd.date_range('2025-01-01', periods=10, freq='D')\n",
        "data = pd.Series(range(10), index=dates)\n",
        "\n",
        "# Accessing data for a specific range\n",
        "print(data['2025-01-03':'2025-01-05'])\n",
        "\n",
        "2. Date and Time Handling\n",
        "- The pd.to_datetime() function converts strings or other formats into datetime objects, which makes it easy to handle various time formats.\n",
        "- The pd.Timestamp and pd.Period objects allow for granular time and period handling.\n",
        "- Example:\n",
        "\n",
        "dates = ['2025-01-01', '2025-02-01', '2025-03-01']\n",
        "datetime_dates = pd.to_datetime(dates)\n",
        "print(datetime_dates)\n",
        "\n",
        "3. Resampling\n",
        "- Resampling allows aggregation or interpolation of data at different time frequencies (e.g., converting daily data to monthly averages).\n",
        "- Example: Aggregating daily data into monthly data.\n",
        "\n",
        "data = pd.Series(range(10), index=pd.date_range('2025-01-01', periods=10, freq='D'))\n",
        "monthly_data = data.resample('M').sum()\n",
        "print(monthly_data)\n",
        "\n",
        "4. Shifting and Lagging\n",
        "- Pandas provides functions like .shift() to move data forward or backward in time, enabling operations like calculating differences or lags.\n",
        "- Example: Calculating daily differences in a time series.\n",
        "\n",
        "data = pd.Series(range(10), index=pd.date_range('2025-01-01', periods=10, freq='D'))\n",
        "daily_difference = data.diff()\n",
        "print(daily_difference)\n",
        "\n",
        "5. Rolling and Expanding Windows\n",
        "- Rolling windows (.rolling()) and expanding windows (.expanding()) allow for calculations over a moving window or cumulative calculations.\n",
        "- Example: Calculating a 3-day rolling average.\n",
        "\n",
        "data = pd.Series(range(10), index=pd.date_range('2025-01-01', periods=10, freq='D'))\n",
        "rolling_average = data.rolling(window=3).mean()\n",
        "print(rolling_average)\n",
        "\n",
        "6. Time Zone Handling\n",
        "- Pandas supports time zones and conversions using the tz argument and .tz_convert() method.\n",
        "- Example: Converting time zones.\n",
        "\n",
        "dates = pd.date_range('2025-01-01', periods=5, freq='D', tz='UTC')\n",
        "local_dates = dates.tz_convert('US/Eastern')\n",
        "print(local_dates)\n",
        "\n",
        "7. Period and Frequency Conversion\n",
        "- Pandas supports PeriodIndex for data with regular intervals (e.g., monthly or quarterly data).\n",
        "- Frequency conversion (.asfreq()) allows switching between granularities (e.g., daily to weekly data).\n",
        "- Example:\n",
        "\n",
        "data = pd.Series(range(10), index=pd.date_range('2025-01-01', periods=10, freq='D'))\n",
        "weekly_data = data.asfreq('W', method='pad')\n",
        "print(weekly_data)\n",
        "\n",
        "8. Datetime Properties\n",
        "- Attributes like .year, .month, .day, and .weekday provide easy access to date components.\n",
        "- Example:\n",
        "\n",
        "dates = pd.date_range('2025-01-01', periods=5, freq='D')\n",
        "print(dates.day)  # Outputs: [1, 2, 3, 4, 5]\n",
        "\n",
        "9. Missing Data Handling\n",
        "- Pandas provides tools like .fillna() and .interpolate() to handle missing values in time series.\n",
        "- Example: Filling missing values with the previous value.\n",
        "\n",
        "data = pd.Series([1, None, 3, None, 5], index=pd.date_range('2025-01-01', periods=5, freq='D'))\n",
        "filled_data = data.fillna(method='ffill')\n",
        "print(filled_data)\n",
        "\n",
        "10. Visualization\n",
        "- Time series data can be visualized directly using Pandas’ built-in .plot() method for quick insights.\n",
        "- Example:\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = pd.Series(range(10), index=pd.date_range('2025-01-01', periods=10, freq='D'))\n",
        "data.plot(title=\"Time Series Plot\")\n",
        "plt.show()\n",
        "\n",
        "11. Integration with Libraries\n",
        "- Pandas integrates seamlessly with other libraries like NumPy and Matplotlib, allowing for advanced statistical analysis and customized visualizations of time series data.\n",
        "\n",
        "12. Time Series-specific Methods\n",
        "- Functions like .truncate(), .at_time(), and .between_time() simplify time-based filtering and slicing.\n",
        "- Example:\n",
        "\n",
        "data = pd.Series(range(24), index=pd.date_range('2025-01-01', periods=24, freq='H'))\n",
        "filtered_data = data.between_time('06:00', '12:00')\n",
        "print(filtered_data)\n",
        "\n",
        "#Summary\n",
        "Pandas simplifies time series analysis by providing robust tools for:\n",
        "\n",
        "- Handling datetime indexing.\n",
        "- Aggregating and resampling.\n",
        "- Managing time zones and missing data.\n",
        "- Performing rolling window calculations.\n",
        "- Visualizing time-based patterns. These features make Pandas an essential library for working with temporal data in Python."
      ],
      "metadata": {
        "id": "0u4PF73HLRCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#20.What is the role of a pivot table in Pandas ?\n"
      ],
      "metadata": {
        "id": "_T27IvRZOi3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A pivot table in Pandas is a powerful tool for summarizing, aggregating, and reshaping data. It is used to calculate, group, and analyze data in a tabular format, similar to pivot tables in spreadsheet applications like Microsoft Excel.\n",
        "\n",
        "#Key Roles of a Pivot Table in Pandas\n",
        "1.Summarizing Data\n",
        "- A pivot table allows you to summarize data by grouping it based on one or more keys (columns) and performing aggregation (e.g., sum, mean, count) on another column.\n",
        "- Example: Summarizing sales data by region and product.\n",
        "\n",
        "2.Reshaping Data\n",
        "- Pivot tables transform data from a long format to a wide format, making it easier to analyze.\n",
        "- Example: Converting a dataset of sales transactions into a table showing monthly sales for each product.\n",
        "\n",
        "3.Custom Aggregations\n",
        "- You can apply custom aggregation functions to calculate metrics like sums, averages, or counts for grouped data.\n",
        "- Example: Calculating the total revenue for each product in a dataset.\n",
        "\n",
        "4.Multi-dimensional Analysis\n",
        "- Pivot tables support hierarchical indexing, enabling multi-level grouping for deeper insights.\n",
        "- Example: Grouping sales data first by region, then by product category.\n",
        "\n",
        "5.Data Exploration\n",
        "- They make it easy to explore data trends, patterns, and relationships by creating summaries tailored to specific questions.\n",
        "- Example: Analyzing how sales vary across different months and regions.\n",
        "\n",
        "#Syntax of pivot_table() in Pandas\n",
        "The pivot_table() method is used to create pivot tables in Pandas. Its key parameters are:\n",
        "\n",
        "- data: The DataFrame to pivot.\n",
        "- values: The column(s) to aggregate.\n",
        "- index: The column(s) to group by (rows).\n",
        "- columns: The column(s) to group by (columns).\n",
        "- aggfunc: The aggregation function(s) to apply (default is numpy.mean).\n",
        "\n",
        "#Example: Creating a Pivot Table\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'Region': ['North', 'South', 'North', 'East', 'South', 'East'],\n",
        "    'Product': ['A', 'B', 'A', 'C', 'B', 'C'],\n",
        "    'Sales': [100, 200, 150, 300, 250, 400],\n",
        "    'Month': ['Jan', 'Jan', 'Feb', 'Feb', 'Jan', 'Feb']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Creating a pivot table\n",
        "pivot = pd.pivot_table(\n",
        "    data=df,\n",
        "    values='Sales',\n",
        "    index='Region',\n",
        "    columns='Month',\n",
        "    aggfunc='sum',\n",
        "    fill_value=0  # Replace NaN with 0\n",
        ")\n",
        "\n",
        "print(pivot)\n",
        "\n",
        "Output of the Example\n",
        "\n",
        "Month\t               Jan\t              Feb\n",
        "East\t                0\t                400\n",
        "North\t               100\t              150\n",
        "South\t               450\t               0\n",
        "- Rows (index): Regions ('Region').\n",
        "- Columns (columns): Months ('Month').\n",
        "- Values (values): Sales ('Sales'), aggregated by summing.\n",
        "\n",
        "#Advantages of Pivot Tables in Pandas\n",
        "1.Efficiency: Handles large datasets and performs aggregations quickly.\n",
        "2.Flexibility: Supports custom aggregation functions and multi-level indexing.\n",
        "3.Ease of Use: Simple syntax for grouping and aggregating data.\n",
        "\n",
        "#Conclusion\n",
        "Pivot tables in Pandas are a crucial tool for summarizing and analyzing data in a flexible and intuitive way. They make it easy to transform and explore datasets, enabling better decision-making and data-driven insights."
      ],
      "metadata": {
        "id": "N0z8Qxh7OqLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#21.Why is NumPy’s array slicing faster than Python’s list slicing ?"
      ],
      "metadata": {
        "id": "YgebUTn0QC9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NumPy's array slicing is faster than Python's list slicing due to the following reasons:\n",
        "\n",
        "1. Memory Contiguity\n",
        "- NumPy arrays store data in contiguous blocks of memory, allowing for efficient access and manipulation.\n",
        "- Python lists, on the other hand, are collections of pointers to objects, which may not be stored contiguously in memory. Accessing elements involves dereferencing these pointers, which adds overhead.\n",
        "2. Homogeneous Data Type\n",
        "- NumPy arrays are homogeneous, meaning all elements have the same data type. This allows NumPy to use optimized, low-level operations implemented in C for slicing and indexing.\n",
        "- Python lists are heterogeneous, meaning each element can be of a different type, requiring type-checking and additional overhead during slicing.\n",
        "3. No Object Overhead\n",
        "- NumPy arrays store raw numerical data, without the overhead of Python objects (e.g., metadata, type information).\n",
        "- In contrast, Python lists store references to Python objects, which increases the complexity of slicing.\n",
        "4. View vs Copy Behavior\n",
        "- When slicing a NumPy array, it creates a view of the original array rather than copying the data. This avoids unnecessary memory allocation and improves speed.\n",
        "- In Python lists, slicing creates a new list (a copy), requiring additional memory and time to copy the elements.\n",
        "5. Optimized Internal Implementation\n",
        "- NumPy slicing is implemented in C and heavily optimized for performance. It leverages vectorized operations and SIMD (Single Instruction Multiple Data) instructions for slicing and other operations.\n",
        "- Python lists rely on generic, less-optimized operations written in Python, which are slower.\n",
        "6. Fewer Abstractions\n",
        "- NumPy arrays operate closer to the hardware level, reducing the overhead caused by Python’s abstractions.\n",
        "- Python lists use higher-level abstractions, which are inherently slower due to the flexibility and dynamic nature of Python.\n",
        "\n",
        "#Illustration of Speed Difference\n",
        "Here’s a practical demonstration of the speed difference using NumPy and Python lists:\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Creating large NumPy array and Python list\n",
        "numpy_array = np.arange(1_000_000)\n",
        "python_list = list(range(1_000_000))\n",
        "\n",
        "# Timing NumPy slicing\n",
        "start = time.time()\n",
        "numpy_slice = numpy_array[100:200_000]\n",
        "end = time.time()\n",
        "print(f\"NumPy slicing time: {end - start:.6f} seconds\")\n",
        "\n",
        "# Timing Python list slicing\n",
        "start = time.time()\n",
        "list_slice = python_list[100:200_000]\n",
        "end = time.time()\n",
        "print(f\"Python list slicing time: {end - start:.6f} seconds\")\n",
        "\n",
        "Example Output\n",
        "\n",
        "NumPy slicing time: 0.000120 seconds\n",
        "Python list slicing time: 0.005143 seconds\n",
        "\n",
        "#Conclusion\n",
        "NumPy’s array slicing is faster than Python’s list slicing because of memory contiguity, homogeneous data types, no object overhead, view-based slicing, optimized implementation, and fewer abstractions. This efficiency is one of the reasons NumPy is widely used for scientific computing and large-scale data processing."
      ],
      "metadata": {
        "id": "pXXdB3aUQIxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#22.What are some common use cases for Seaborn?"
      ],
      "metadata": {
        "id": "JexcidUFQ9q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Seaborn is a powerful Python library for data visualization that builds on Matplotlib and provides an interface for creating attractive and informative statistical graphics. Its simplicity and ability to create complex plots with minimal code make it ideal for various use cases. Here are some common use cases for Seaborn:\n",
        "\n",
        "1. Exploratory Data Analysis (EDA)\n",
        "- Seaborn's statistical visualizations are well-suited for exploring datasets to identify patterns, trends, correlations, and outliers.\n",
        "- Example: Using pairplot to visualize pairwise relationships in a dataset.\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "data = sns.load_dataset('iris')\n",
        "sns.pairplot(data, hue='species')\n",
        "\n",
        "2. Visualizing Distributions\n",
        "- Seaborn provides specialized plots for visualizing the distribution of data, such as histograms, kernel density plots, and box plots.\n",
        "- Example: Using sns.histplot and sns.boxplot.\n",
        "\n",
        "sns.histplot(data['sepal_length'], kde=True)\n",
        "sns.boxplot(x='species', y='sepal_length', data=data)\n",
        "\n",
        "3. Correlation and Heatmaps\n",
        "- Seaborn simplifies creating heatmaps to visualize correlations or other matrix-like data.\n",
        "- Example: Creating a heatmap for a correlation matrix.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Correlation matrix\n",
        "correlation_matrix = data.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "\n",
        "4. Time Series Analysis\n",
        "- Seaborn can visualize time series data to show trends over time using line plots.\n",
        "- Example: Plotting stock prices or temperature over time.\n",
        "\n",
        "# Example time series plot\n",
        "sns.lineplot(x='time', y='value', data=time_series_data)\n",
        "\n",
        "5. Categorical Data Visualization\n",
        "- Seaborn offers various tools for visualizing categorical data, such as bar plots, count plots, and swarm plots.\n",
        "- Example: Visualizing sales by product category.\n",
        "\n",
        "sns.barplot(x='category', y='sales', data=sales_data)\n",
        "sns.countplot(x='product', data=sales_data)\n",
        "\n",
        "6. Comparing Distributions Across Groups\n",
        "- Seaborn can compare distributions across different categories using violin plots, box plots, and strip plots.\n",
        "- Example: Comparing test scores across different schools.\n",
        "\n",
        "sns.violinplot(x='school', y='test_score', data=education_data)\n",
        "\n",
        "7. Regression Analysis\n",
        "- Seaborn provides tools like sns.regplot and sns.lmplot to visualize relationships and fit regression lines.\n",
        "- Example: Analyzing the relationship between advertising spend and sales.\n",
        "\n",
        "sns.regplot(x='advertising_spend', y='sales', data=marketing_data)\n",
        "\n",
        "8. Faceted Plots\n",
        "- Seaborn's FacetGrid and related functions allow creating subplots (facets) for different subsets of data, enabling comparisons across categories or conditions.\n",
        "- Example: Visualizing sales trends by region.\n",
        "\n",
        "g = sns.FacetGrid(data=sales_data, col='region', hue='product')\n",
        "g.map(sns.lineplot, 'month', 'sales')\n",
        "g.add_legend()\n",
        "\n",
        "9. Statistical Visualization\n",
        "- Seaborn integrates statistical estimation into visualizations, such as confidence intervals in line plots or mean/median annotations in bar plots.\n",
        "- Example: Showing confidence intervals for a trend line.\n",
        "\n",
        "sns.lineplot(x='time', y='value', data=data, ci='sd')\n",
        "\n",
        "10. Customizing and Styling Plots\n",
        "- Seaborn makes it easy to customize plot aesthetics with themes, palettes, and advanced settings.\n",
        "- Example: Applying a custom theme.\n",
        "\n",
        "sns.set_theme(style='whitegrid')\n",
        "sns.boxplot(x='species', y='sepal_width', data=data)\n",
        "\n",
        "#Common Applications\n",
        "1.Data Science: EDA, feature analysis, and model evaluation.\n",
        "2.Finance: Visualizing stock price trends, correlations, and portfolio performance.\n",
        "3.Healthcare: Analyzing patient data distributions, trends, and treatment effects.\n",
        "4.Marketing: Comparing campaign performance, sales trends, and customer behavior.\n",
        "5.Education: Comparing student performance, attendance, or resource utilization.\n",
        "\n",
        "#Conclusion\n",
        "Seaborn is widely used for creating statistical graphics and simplifying data exploration and analysis. Its user-friendly interface, ability to handle complex visualizations, and integration with Matplotlib make it a go-to tool for data visualization tasks."
      ],
      "metadata": {
        "id": "5TeV_jVBRX7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practical Questions**"
      ],
      "metadata": {
        "id": "Wpg3C0hoSDai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.How do you create a 2D NumPy array and calculate the sum of each row ?"
      ],
      "metadata": {
        "id": "s1-Eyjx1SMzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Here's we can create a 2D NumPy array and calculate the sum of each row:\n",
        "\n",
        "#Step 1: Import NumPy\n",
        "Start by importing the NumPy library.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#Step 2: Create a 2D NumPy Array\n",
        "You can create a 2D array using np.array().\n",
        "\n",
        "# Creating a 2D NumPy array\n",
        "array_2d = np.array([[1, 2, 3],\n",
        "                     [4, 5, 6],\n",
        "                     [7, 8, 9]])\n",
        "print(\"2D Array:\")\n",
        "print(array_2d)\n",
        "\n",
        "#Step 3: Calculate the Row-wise Sum\n",
        "Use the np.sum() function with the axis parameter set to 1 to calculate the sum of each row.\n",
        "\n",
        "# Calculate row-wise sums\n",
        "row_sums = np.sum(array_2d, axis=1)\n",
        "print(\"\\nSum of each row:\")\n",
        "print(row_sums)\n",
        "\n",
        "#Full Code Example\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Create a 2D array\n",
        "array_2d = np.array([[1, 2, 3],\n",
        "                     [4, 5, 6],\n",
        "                     [7, 8, 9]])\n",
        "\n",
        "print(\"2D Array:\")\n",
        "print(array_2d)\n",
        "\n",
        "# Step 2: Calculate the sum of each row\n",
        "row_sums = np.sum(array_2d, axis=1)\n",
        "\n",
        "print(\"\\nSum of each row:\")\n",
        "print(row_sums)\n",
        "\n",
        "Output\n",
        "\n",
        "2D Array:\n",
        "[[1 2 3]\n",
        " [4 5 6]\n",
        " [7 8 9]]\n",
        "\n",
        "Sum of each row:\n",
        "[ 6 15 24]\n",
        "\n",
        "#Explanation\n",
        "- np.array(): Creates a NumPy array.\n",
        "- np.sum(array_2d, axis=1):\n",
        "  - The axis=1 parameter specifies that the sum should be computed across columns for each row (i.e., row-wise).\n",
        "  - If axis=0, the sum would be calculated column-wise.\n",
        "This approach is efficient and leverages NumPy's optimized operations for array computations."
      ],
      "metadata": {
        "id": "2brkw3_iSR3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.Write a Pandas script to find the mean of a specific column in a DataFrame ?"
      ],
      "metadata": {
        "id": "gfcNyqZ-TGHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Here’s a Python script that uses Pandas to calculate the mean of a specific column in a DataFrame:\n",
        "\n",
        "#Code Example\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {\n",
        "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
        "    \"Age\": [25, 30, 35, 40],\n",
        "    \"Salary\": [50000, 60000, 55000, 70000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the mean of a specific column (e.g., \"Salary\")\n",
        "mean_salary = df[\"Salary\"].mean()\n",
        "\n",
        "print(\"Mean Salary:\", mean_salary)\n",
        "\n",
        "#Explanation\n",
        "1.pd.DataFrame():\n",
        "- Creates a DataFrame from the given dictionary.\n",
        "2.Accessing a Column:\n",
        "- Use df[\"Salary\"] to select the \"Salary\" column.\n",
        "3.mean():\n",
        "- The mean() method computes the arithmetic mean of the selected column.\n",
        "\n",
        "Output\n",
        "\n",
        "Mean Salary: 58750.0\n",
        "\n",
        "#Note\n",
        "- Replace \"Salary\" with the name of the column for which you want to calculate the mean.\n",
        "- Ensure the column contains numerical data; otherwise, Pandas will raise an error."
      ],
      "metadata": {
        "id": "MzPpwVaoTLv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.Create a scatter plot using Matplotlib ?"
      ],
      "metadata": {
        "id": "HLtXfev7TqLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Here’s how we can create a scatter plot using Matplotlib:\n",
        "\n",
        "#Code Example\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data\n",
        "x = [5, 7, 8, 7, 2, 17, 2, 9, 4, 11]\n",
        "y = [99, 86, 87, 88, 100, 86, 103, 87, 94, 78]\n",
        "\n",
        "# Create scatter plot\n",
        "plt.scatter(x, y, color='blue', label='Data Points')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title(\"Scatter Plot Example\")\n",
        "plt.xlabel(\"X-axis Label\")\n",
        "plt.ylabel(\"Y-axis Label\")\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "#Explanation\n",
        "1.plt.scatter(x, y):\n",
        "- Creates a scatter plot using x and y as the coordinates of the points.\n",
        "2.Customization:\n",
        "- color='blue': Specifies the color of the points.\n",
        "- label='Data Points': Adds a label for the points, useful for legends.\n",
        "3.plt.title(), plt.xlabel(), plt.ylabel():\n",
        "- Add a title and labels to the axes.\n",
        "4.plt.legend():\n",
        "- Displays the legend for the scatter plot.\n",
        "5.plt.show():\n",
        "- Renders and displays the plot.\n",
        "\n",
        "Output\n",
        "A scatter plot with the given x and y values will be displayed. It will include:\n",
        "\n",
        "- A blue scatter of points.\n",
        "- A title and axis labels.\n",
        "- A legend indicating the data points.\n",
        "You can modify the x and y values, colors, or labels to customize the plot further."
      ],
      "metadata": {
        "id": "YmhWVwX9Tuj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.How do you calculate the correlation matrix using Seaborn and visualize it with a heatmap ?\n"
      ],
      "metadata": {
        "id": "dbybjOMRUU9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Steps to Calculate the Correlation Matrix and Visualize it with Seaborn\n",
        "1.Import Required Libraries: Import Pandas, NumPy, and Seaborn.\n",
        "2.Prepare Your Data: Load or create a dataset.\n",
        "3.Calculate the Correlation Matrix: Use the .corr() method in Pandas to calculate correlations.\n",
        "4.Create a Heatmap: Use Seaborn’s heatmap() to visualize the correlation matrix.\n",
        "\n",
        "#Code Example\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {\n",
        "    \"Math\": [78, 85, 96, 80, 70],\n",
        "    \"Science\": [88, 92, 94, 78, 85],\n",
        "    \"English\": [82, 90, 88, 80, 78],\n",
        "    \"History\": [75, 80, 85, 70, 68]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Display the correlation matrix\n",
        "print(\"Correlation Matrix:\")\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Create a heatmap\n",
        "sns.set_theme(style=\"white\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "\n",
        "# Add a title\n",
        "plt.title(\"Correlation Matrix Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "#Explanation\n",
        "1.DataFrame Creation:\n",
        "\n",
        "- A dictionary is used to create a Pandas DataFrame.\n",
        "2.Correlation Calculation:\n",
        "\n",
        "- .corr(): Computes pairwise correlation of columns (default method is Pearson correlation).\n",
        "3.Heatmap Visualization:\n",
        "\n",
        "- sns.heatmap():\n",
        "- annot=True: Annotates each cell with the correlation value.\n",
        "- cmap=\"coolwarm\": Sets the color map for the heatmap.\n",
        "- fmt=\".2f\": Formats the numbers to two decimal places.\n",
        "4.Styling:\n",
        "\n",
        "- sns.set_theme(): Sets a consistent style.\n",
        "- plt.title(): Adds a title for context.\n",
        "\n",
        "Output\n",
        "- Console Output: The correlation matrix printed in tabular form.\n",
        "\n",
        "Example:\n",
        "\n",
        "Correlation Matrix:\n",
        "          Math  Science  English  History\n",
        "Math      1.00     0.82     0.72     0.70\n",
        "Science   0.82     1.00     0.66     0.60\n",
        "English   0.72     0.66     1.00     0.58\n",
        "History   0.70     0.60     0.58     1.00\n",
        "\n",
        "Plot Output: A heatmap showing the correlation values with a gradient color map.\n",
        "\n",
        "#Applications\n",
        "- Identifying strong positive or negative relationships between variables.\n",
        "- Visualizing relationships for exploratory data analysis (EDA)."
      ],
      "metadata": {
        "id": "nzo1ixLbUbCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.Generate a bar plot using Plotly ?"
      ],
      "metadata": {
        "id": "CLaCIwrCVVr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Here’s how we can generate a bar plot using Plotly:\n",
        "\n",
        "#Code Example\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Sample data\n",
        "categories = ['A', 'B', 'C', 'D']\n",
        "values = [10, 15, 7, 12]\n",
        "\n",
        "# Create a bar plot\n",
        "fig = go.Figure(data=[\n",
        "    go.Bar(x=categories, y=values, marker_color='skyblue', name='Sample Data')\n",
        "])\n",
        "\n",
        "# Add title and labels\n",
        "fig.update_layout(\n",
        "    title='Bar Plot Example',\n",
        "    xaxis_title='Categories',\n",
        "    yaxis_title='Values',\n",
        "    template='plotly'\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n",
        "\n",
        "#Explanation\n",
        "1.Import Plotly:\n",
        "\n",
        "- Import plotly.graph_objects as go for creating the bar plot.\n",
        "2.Data Preparation:\n",
        "\n",
        "- Define the categories (x-axis) and corresponding values (y-axis).\n",
        "3.Create Bar Plot:\n",
        "\n",
        "- Use go.Bar() to create the bar chart.\n",
        "- marker_color='skyblue': Sets the color of the bars.\n",
        "- name='Sample Data': Adds a label for the dataset.\n",
        "4.Customize Layout:\n",
        "\n",
        "- Use fig.update_layout() to set the title, x-axis, y-axis labels, and theme.\n",
        "5.Display the Plot:\n",
        "\n",
        "- Use fig.show() to render the plot in your browser or Jupyter Notebook.\n",
        "\n",
        "Output\n",
        "\n",
        "A bar chart with categories on the x-axis and their respective values on the y-axis.\n",
        "The bars will be styled with a sky-blue color, and the plot will have a title and axis labels.\n",
        "\n",
        "#Advantages of Plotly for Bar Plots\n",
        "1.Interactivity: Hover tooltips, zooming, and panning.\n",
        "2.Customization: Easily styled with colors, labels, and annotations.\n",
        "3.Ease of Use: Simple integration with Python and intuitive API.\n",
        "You can modify the data, colors, or layout to suit your needs!"
      ],
      "metadata": {
        "id": "l1BCh9sHVr-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6.Create a DataFrame and add a new column based on an existing column ?"
      ],
      "metadata": {
        "id": "jBBr3aflXEg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Here's an example of how you can create a DataFrame and add a new column based on an existing one using Python and pandas:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {\n",
        "    'A': [1, 2, 3, 4, 5],\n",
        "    'B': [10, 20, 30, 40, 50]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Add a new column 'C' based on column 'A'\n",
        "df['C'] = df['A'] * 2  # Here, column C is the result of multiplying values in column A by 2\n",
        "\n",
        "print(df)\n",
        "\n",
        "Output:\n",
        "\n",
        "   A   B  C\n",
        "0  1  10  2\n",
        "1  2  20  4\n",
        "2  3  30  6\n",
        "3  4  40  8\n",
        "4  5  50  10\n",
        "\n",
        "In this example:\n",
        "\n",
        "A new column 'C' is created by multiplying the values in column 'A' by 2. You can adjust the logic to suit your needs."
      ],
      "metadata": {
        "id": "ajrgRBMYXKjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7.Write a program to perform element-wise multiplication of two NumPy arrays ?"
      ],
      "metadata": {
        "id": "Krei92elXre-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Here’s a Python program to perform element-wise multiplication of two NumPy arrays:\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Create two NumPy arrays\n",
        "array1 = np.array([1, 2, 3, 4, 5])\n",
        "array2 = np.array([10, 20, 30, 40, 50])\n",
        "\n",
        "# Perform element-wise multiplication\n",
        "result = array1 * array2\n",
        "\n",
        "# Print the result\n",
        "print(\"Element-wise multiplication result:\", result)\n",
        "\n",
        "Output:\n",
        "\n",
        "Element-wise multiplication result: [ 10  40  90 160 250]\n",
        "\n",
        "#In this example:\n",
        "\n",
        "- Two NumPy arrays, array1 and array2, are created.\n",
        "- Element-wise multiplication is performed using the * operator, and the result is stored in result."
      ],
      "metadata": {
        "id": "1WDzE6WoX6QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8.Create a line plot with multiple lines using Matplotlib ?"
      ],
      "metadata": {
        "id": "YYPbYF_qYHKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Here's an example of how to create a line plot with multiple lines using Matplotlib:\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Create data for multiple lines\n",
        "x = np.linspace(0, 10, 100)  # 100 points between 0 and 10\n",
        "y1 = np.sin(x)  # First line: sine of x\n",
        "y2 = np.cos(x)  # Second line: cosine of x\n",
        "y3 = np.tan(x)  # Third line: tangent of x\n",
        "\n",
        "# Create the plot\n",
        "plt.plot(x, y1, label='sin(x)', color='blue')  # Plot first line (sin)\n",
        "plt.plot(x, y2, label='cos(x)', color='green')  # Plot second line (cos)\n",
        "plt.plot(x, y3, label='tan(x)', color='red')  # Plot third line (tan)\n",
        "\n",
        "# Adding titles and labels\n",
        "plt.title('Multiple Lines Plot')\n",
        "plt.xlabel('x values')\n",
        "plt.ylabel('y values')\n",
        "\n",
        "# Add a legend to distinguish the lines\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#Explanation:\n",
        "- x is an array of 100 points between 0 and 10.\n",
        "- Three different mathematical functions (sin(x), cos(x), and tan(x)) are plotted as separate lines.\n",
        "- Each plt.plot() call plots one of these functions with a different color and label.\n",
        "- plt.legend() adds the legend to identify each line.\n",
        "- The plot is displayed using plt.show(), with a grid added for clarity.\n",
        "This will display a line plot with three different functions (sin(x), cos(x), and tan(x)) on the same graph."
      ],
      "metadata": {
        "id": "brn6rzvfYMj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9. Generate a Pandas DataFrame and filter rows where a column value is greater than a threshold ?"
      ],
      "metadata": {
        "id": "c8_yTmARYca6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Here’s how we can generate a Pandas DataFrame and filter rows where the values in a specified column are greater than a given threshold:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {\n",
        "    'A': [1, 2, 3, 4, 5],\n",
        "    'B': [10, 20, 30, 40, 50]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set a threshold value for column 'B'\n",
        "threshold = 30\n",
        "\n",
        "# Filter rows where values in column 'B' are greater than the threshold\n",
        "filtered_df = df[df['B'] > threshold]\n",
        "\n",
        "# Print the filtered DataFrame\n",
        "print(filtered_df)\n",
        "\n",
        "Output:\n",
        "\n",
        "   A   B\n",
        "3  4  40\n",
        "4  5  50\n",
        "\n",
        "#Explanation:\n",
        "- A DataFrame df is created with two columns, 'A' and 'B'.\n",
        "- The filter condition df['B'] > threshold is used to select rows where the values in column 'B' are greater than the threshold (30 in this case).\n",
        "- The filtered DataFrame is stored in filtered_df and printed."
      ],
      "metadata": {
        "id": "8jxaz3BxYiQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10.Create a histogram using Seaborn to visualize a distribution ?"
      ],
      "metadata": {
        "id": "KO069hSrYzwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Here's an example of how to create a histogram using Seaborn to visualize a distribution:\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Generate random data for the distribution\n",
        "data = np.random.randn(1000)  # 1000 random numbers from a standard normal distribution\n",
        "\n",
        "# Create a histogram with Seaborn\n",
        "sns.histplot(data, kde=True, bins=30, color='skyblue', edgecolor='black')\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Distribution of Random Data')\n",
        "plt.xlabel('Values')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "#Explanation:\n",
        "- data is generated using NumPy’s np.random.randn(1000), which creates 1000 random values from a standard normal distribution.\n",
        "- sns.histplot() is used to create the histogram. The kde=True argument adds a Kernel Density Estimate (KDE) line to visualize the distribution more smoothly.\n",
        "- bins=30 specifies the number of bins for the histogram.\n",
        "- color='skyblue' and edgecolor='black' are used to customize the appearance of the bars.\n",
        "This will produce a histogram with a KDE curve overlaid, visualizing the distribution of the data."
      ],
      "metadata": {
        "id": "3XD0EUOsY6VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11.Perform matrix multiplication using NumPy ?"
      ],
      "metadata": {
        "id": "VP3gd6w_ZLvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Here's an example of how to perform matrix multiplication using NumPy:\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Define two matrices A and B\n",
        "A = np.array([[1, 2], [3, 4]])\n",
        "B = np.array([[5, 6], [7, 8]])\n",
        "\n",
        "# Perform matrix multiplication\n",
        "result = np.dot(A, B)  # Or equivalently: result = A @ B\n",
        "\n",
        "# Print the result\n",
        "print(\"Matrix multiplication result:\")\n",
        "print(result)\n",
        "\n",
        "Output:\n",
        "\n",
        "Matrix multiplication result:\n",
        "[[19 22]\n",
        " [43 50]]\n",
        "\n",
        "#Explanation:\n",
        "- A and B are two 2x2 matrices.\n",
        "- np.dot(A, B) performs the matrix multiplication of A and B. You can also use the @ operator for the same result (A @ B).\n",
        "- The result is a new matrix obtained by multiplying corresponding rows of A with columns of B.\n",
        "\n",
        "In this example:\n",
        "\n",
        "- The first row of A is [1, 2], and the first column of B is [5, 7]. The multiplication results in 1*5 + 2*7 = 19, and similarly for the other elements."
      ],
      "metadata": {
        "id": "poovJa-OZRPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#12.Use Pandas to load a CSV file and display its first 5 rows ?"
      ],
      "metadata": {
        "id": "fjBGLt3Kddan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Here's how we can use Pandas to load a CSV file and display its first 5 rows:\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv('your_file.csv')  # Replace 'your_file.csv' with the actual path to your CSV file\n",
        "\n",
        "# Display the first 5 rows of the DataFrame\n",
        "print(df.head())  # By default, head() returns the first 5 rows\n",
        "\n",
        "#Explanation:\n",
        "- pd.read_csv('your_file.csv') loads the CSV file into a Pandas DataFrame.\n",
        "- df.head() displays the first 5 rows of the DataFrame by default.\n",
        "Make sure that 'your_file.csv' points to the correct path of the CSV file. You can also specify a different number of rows by passing an integer to head(), such as df.head(10) to display the first 10 rows."
      ],
      "metadata": {
        "id": "nGDg2yHNdkP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#13.Create a 3D scatter plot using Plotly ?"
      ],
      "metadata": {
        "id": "4tV5lO4sdy68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Here's an example of how to create a 3D scatter plot using Plotly:\n",
        "\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Generate random data for 3D scatter plot\n",
        "np.random.seed(42)\n",
        "data = {\n",
        "    'x': np.random.rand(100),\n",
        "    'y': np.random.rand(100),\n",
        "    'z': np.random.rand(100),\n",
        "    'color': np.random.rand(100)  # Color dimension for each point\n",
        "}\n",
        "\n",
        "# Create a DataFrame from the data\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create the 3D scatter plot\n",
        "fig = px.scatter_3d(df, x='x', y='y', z='z', color='color',\n",
        "                    title=\"3D Scatter Plot\",\n",
        "                    labels={'x': 'X Axis', 'y': 'Y Axis', 'z': 'Z Axis'})\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n",
        "\n",
        "#Explanation:\n",
        "- np.random.rand(100) generates 100 random values between 0 and 1 for x, y, and z coordinates.\n",
        "- The color column is also created to provide a coloring scheme based on the values.\n",
        "- px.scatter_3d() is used to create a 3D scatter plot. The x, y, and z parameters specify the columns in the DataFrame, and color adds color to each point based on its corresponding value.\n",
        "- fig.show() renders the plot.\n",
        "When we run this code, you'll get an interactive 3D scatter plot where you can rotate and zoom in/out."
      ],
      "metadata": {
        "id": "SGii3-Mid3kB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}